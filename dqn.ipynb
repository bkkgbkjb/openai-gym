{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804dd343",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import gym\n",
    "\n",
    "from typing import List, Tuple, Literal, Any, Optional, cast, Callable\n",
    "import plotly.graph_objects as go\n",
    "from utils.agent import Agent\n",
    "from tqdm.autonotebook import tqdm\n",
    "from utils.algorithm import AlgorithmInterface\n",
    "from utils.preprocess import PreprocessInterface\n",
    "import torch\n",
    "from collections import deque\n",
    "from torchvision import transforms\n",
    "import math\n",
    "from torch import nn\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from utils.common import Step, Episode, TransitionGeneric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba56515b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7b105b60b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d494e7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f93d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"PongNoFrameskip-v4\")\n",
    "env.seed(RANDOM_SEED)\n",
    "env.reset()\n",
    "env._max_episode_steps = 1_0000\n",
    "TOTAL_ACTIONS = env.action_space.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c43d75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7746b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape is (210, 160, 3)\n",
    "Observation = npt.NDArray[np.uint8]\n",
    "Action = int\n",
    "\n",
    "# shape is (4, 210, 160, 3)\n",
    "State = torch.Tensor\n",
    "Reward = int\n",
    "\n",
    "Transition = TransitionGeneric[State, Action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3e29eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, (8, 8), 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (4, 4), 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (3, 3), 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7 * 7 * 64, 512),\n",
    "            nn.Linear(512, TOTAL_ACTIONS),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x: State) -> torch.Tensor:\n",
    "        rlt = cast(torch.Tensor, self.net(x.to(device)))\n",
    "        assert rlt.shape == (x.shape[0], TOTAL_ACTIONS)\n",
    "        return rlt.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415e8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAlgorithm(AlgorithmInterface[State, Action]):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.times = 1\n",
    "        self.last_action = None\n",
    "\n",
    "    def allowed_actions(self, state: State) -> List[Action]:\n",
    "        return list(range(TOTAL_ACTIONS))\n",
    "\n",
    "    def take_action(self, state: State) -> Action:\n",
    "        self.times += 1\n",
    "\n",
    "        if self.times % 10 == 0:\n",
    "            act = np.random.choice(self.allowed_actions(state))\n",
    "            self.last_action = act\n",
    "            return act\n",
    "\n",
    "        if self.last_action is not None:\n",
    "            return self.last_action\n",
    "\n",
    "        act = np.random.choice(self.allowed_actions(state))\n",
    "        self.last_action = act\n",
    "        return act\n",
    "\n",
    "    def after_step(\n",
    "        self,\n",
    "        sa: Tuple[State, Action],\n",
    "        episode: Episode[State, Action],\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def on_termination(self, episode: Episode[State, Action]):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a37d4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNAlgorithm(AlgorithmInterface[State, Action]):\n",
    "    def __init__(self, nn: DQN, training_times: int = 50_00_0000, gamma: float = 0.99):\n",
    "        self.network = nn\n",
    "        self.optimizer = torch.optim.RMSprop(\n",
    "            self.network.parameters(), 1e-3, 0.95, 0.01\n",
    "        )\n",
    "\n",
    "        self.frame_skip = 4\n",
    "        self.last_action = None\n",
    "\n",
    "        self.shrink = min(training_times / 50_00_0000, 1)\n",
    "        if self.shrink != 1:\n",
    "            print(f\"training on shrinked mode: {self.shrink}\")\n",
    "\n",
    "        self.target_network = DQN()\n",
    "        self.target_network.load_state_dict(self.network.state_dict())\n",
    "\n",
    "        self.times: int = 1\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.update_freq: int = 4\n",
    "        self.update_target = 250\n",
    "\n",
    "        self.memory_replay: deque[Transition] = deque(\n",
    "            maxlen=math.ceil(1_0000 * self.shrink)\n",
    "        )\n",
    "        self.gamma = gamma\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def allowed_actions(self, _: State) -> List[Action]:\n",
    "        return list(range(TOTAL_ACTIONS))\n",
    "\n",
    "    def get_action(self, state: State) -> Action:\n",
    "        rand = np.random.random()\n",
    "        max_decry_times = 100_0000 * self.shrink\n",
    "        sigma = 1 - 0.9 / max_decry_times * \\\n",
    "            np.min([self.times, max_decry_times])\n",
    "        if rand < sigma:\n",
    "            return np.random.choice(self.allowed_actions(state))\n",
    "        else:\n",
    "            act_vals: torch.Tensor = self.network(state)\n",
    "            maxi = torch.argmax(act_vals)\n",
    "            return cast(Action, maxi)\n",
    "\n",
    "    def take_action(self, state: State) -> Action:\n",
    "\n",
    "        if self.times % self.frame_skip == 0:\n",
    "            self.last_action = self.get_action(state)\n",
    "            return self.last_action\n",
    "\n",
    "        if self.last_action is not None:\n",
    "            return self.last_action\n",
    "\n",
    "        self.last_action = self.get_action(state)\n",
    "        return self.last_action\n",
    "\n",
    "    def after_step(\n",
    "        self,\n",
    "        sa: Tuple[State, Optional[Action]],\n",
    "        episode: Episode[State, Action],\n",
    "    ):\n",
    "        (s, a, r) = episode[-1]\n",
    "        (sn, an) = sa\n",
    "        self.memory_replay.append((s, cast(Action, a), cast(float, r), sn, an))\n",
    "\n",
    "        if self.times % self.update_freq == 0 and len(self.memory_replay) >= 48:\n",
    "\n",
    "            batch: List[Transition] = []\n",
    "            for i in np.random.randint(0, len(self.memory_replay), 32):\n",
    "                batch.append(self.memory_replay[i])\n",
    "\n",
    "            self.train(batch)\n",
    "\n",
    "        if self.times % (self.update_target * self.update_freq) == 0:\n",
    "            self.update_target_network()\n",
    "\n",
    "        self.times += 1\n",
    "\n",
    "    def on_termination(self, episode: Episode[State, Action]):\n",
    "        pass\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.network.state_dict())\n",
    "        # pass\n",
    "\n",
    "    def clip_reward(self, r: float) -> float:\n",
    "        if r > 0:\n",
    "            return 1.0\n",
    "        elif r < 0:\n",
    "            return -1.0\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def train(self, batch: List[Transition]):\n",
    "        # target = torch.tensor(\n",
    "        #     [\n",
    "        #         self.clip_reward(r)\n",
    "        #         if an is None\n",
    "        #         else self.clip_reward(r)\n",
    "        #         + self.gamma * torch.max(self.target_network(sn))\n",
    "        #         for (_, _, r, sn, an) in batch\n",
    "        #     ]\n",
    "        # )\n",
    "\n",
    "        masks = torch.tensor(\n",
    "            [0 if an is None else 1 for (_, _, _, _, an) in batch],\n",
    "            dtype=torch.float,\n",
    "        )\n",
    "\n",
    "        target = torch.tensor(\n",
    "            [self.clip_reward(r) for (_, _, r, _, _) in batch], dtype=torch.float\n",
    "        ) + torch.inner(\n",
    "            masks,\n",
    "            self.gamma\n",
    "            * torch.max(\n",
    "                self.network(torch.cat([sn for (_, _, _, sn, _) in batch])), dim=1\n",
    "            )[0],\n",
    "        )\n",
    "\n",
    "        assert target.shape == (32,)\n",
    "        x_vals = self.network(torch.cat([s for (s, _, _, _, _) in batch]))\n",
    "        x = x_vals[range(x_vals.shape[0]), [a for (_, a, _, _, _) in batch]]\n",
    "\n",
    "        assert x.shape == (32,)\n",
    "\n",
    "        loss = self.loss_func(x, target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "class Preprocess(PreprocessInterface[Observation, Action, State]):\n",
    "    def __init__(self):\n",
    "        self.trfm: Callable[[Observation], State] = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Grayscale(),\n",
    "             transforms.Resize((84, 84))]\n",
    "        )\n",
    "        self.reset()\n",
    "        # self.history: Episode[State, Action] = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.history: Episode[State, Action] = []\n",
    "\n",
    "    def get_current_state(self, h: Episode[Observation, Action]) -> State:\n",
    "        assert len(h) > 0\n",
    "\n",
    "        last_4_arr = self.stack_4(h, -1)\n",
    "\n",
    "        rlt = torch.cat([self.trfm(i)\n",
    "                         for i in last_4_arr]).unsqueeze(0)\n",
    "        assert rlt.shape == (1, 4, 84, 84)\n",
    "        return rlt\n",
    "\n",
    "    def stack_4(\n",
    "        self, h: Episode[Observation, Action], idx: int\n",
    "    ) -> npt.NDArray[np.uint8]:\n",
    "\n",
    "        assert idx < 0\n",
    "        last_4_index = [-3 + idx, -2 + idx, -1 + idx, idx]\n",
    "\n",
    "        last_4: List[Observation] = []\n",
    "        for idx in last_4_index:\n",
    "            if -idx <= len(h):\n",
    "                last_4.append(np.asarray((h[idx][0])))\n",
    "\n",
    "        last_4_arr = np.asarray(last_4)\n",
    "        while last_4_arr.shape[0] < 4:\n",
    "            last_4_arr = np.insert(last_4_arr, 0, last_4[0], axis=0)\n",
    "\n",
    "        assert last_4_arr.shape == (4, 210, 160, 3)\n",
    "\n",
    "        return last_4_arr\n",
    "\n",
    "    def transform_history(\n",
    "        self, h: Episode[Observation, Action]\n",
    "    ) -> Episode[State, Action]:\n",
    "        delta = len(h) - len(self.history)\n",
    "        assert delta == 1\n",
    "\n",
    "        (_, a, r) = h[-1]\n",
    "        last_4_arr = self.stack_4(h, -1)\n",
    "        s = torch.cat([self.trfm(i)\n",
    "                       for i in last_4_arr]).unsqueeze(0)\n",
    "        assert s.shape == (1, 4, 84, 84)\n",
    "        self.history.append((s, a, r))\n",
    "\n",
    "        return self.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd632695",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 83911/50000000 [11:26<113:21:59, 122.31it/s, rwd=-21]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=12'>13</a>\u001b[0m end \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=14'>15</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m end \u001b[39mand\u001b[39;00m frames \u001b[39m<\u001b[39m TRAINING_TIMES:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=15'>16</a>\u001b[0m     (o, end, episode) \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=17'>18</a>\u001b[0m     \u001b[39m# agent.render('human')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=18'>19</a>\u001b[0m     frames \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/openai-gym/utils/agent.py:80\u001b[0m, in \u001b[0;36mAgent.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=70'>71</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode\u001b[39m.\u001b[39mappend((obs, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=72'>73</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready_act \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=73'>74</a>\u001b[0m     \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=74'>75</a>\u001b[0m     \u001b[39mif\u001b[39;00m stop\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=75'>76</a>\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgm\u001b[39m.\u001b[39mtake_action(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess\u001b[39m.\u001b[39mget_current_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode))\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=76'>77</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=78'>79</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimprov \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgm\u001b[39m.\u001b[39mafter_step(\n\u001b[0;32m---> <a href='file:///~/openai-gym/utils/agent.py?line=79'>80</a>\u001b[0m     (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess\u001b[39m.\u001b[39;49mget_current_state(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepisode), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready_act),\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=80'>81</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess\u001b[39m.\u001b[39mtransform_history(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]),\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=81'>82</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=83'>84</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stop:\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=84'>85</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (obs, stop, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 9'\u001b[0m in \u001b[0;36mPreprocess.get_current_state\u001b[0;34m(self, h)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=148'>149</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(h) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=150'>151</a>\u001b[0m last_4_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_4(h, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=152'>153</a>\u001b[0m rlt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrfm(i)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=153'>154</a>\u001b[0m                  \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m last_4_arr])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=154'>155</a>\u001b[0m \u001b[39massert\u001b[39;00m rlt\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m84\u001b[39m, \u001b[39m84\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=155'>156</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rlt\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 9'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=148'>149</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(h) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=150'>151</a>\u001b[0m last_4_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_4(h, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=152'>153</a>\u001b[0m rlt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrfm(i)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=153'>154</a>\u001b[0m                  \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m last_4_arr])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=154'>155</a>\u001b[0m \u001b[39massert\u001b[39;00m rlt\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m84\u001b[39m, \u001b[39m84\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=155'>156</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rlt\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:61\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=58'>59</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=59'>60</a>\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=60'>61</a>\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:98\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=90'>91</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=91'>92</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=92'>93</a>\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=95'>96</a>\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=96'>97</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=97'>98</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py:126\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=122'>123</a>\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=123'>124</a>\u001b[0m     pic \u001b[39m=\u001b[39m pic[:, :, \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=125'>126</a>\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(pic\u001b[39m.\u001b[39;49mtranspose((\u001b[39m2\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)))\u001b[39m.\u001b[39;49mcontiguous()\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=126'>127</a>\u001b[0m \u001b[39m# backward compatibility\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=127'>128</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRAINING_TIMES = 50_00_0000\n",
    "# TRAINING_TIMES = 2_0000\n",
    "\n",
    "agent = Agent(env, NNAlgorithm(DQN(), TRAINING_TIMES), Preprocess())\n",
    "training_rwds: List[float] = []\n",
    "\n",
    "with tqdm(total=TRAINING_TIMES) as pbar:\n",
    "    pbar.update(1)\n",
    "    frames = 1\n",
    "    while frames < TRAINING_TIMES:\n",
    "        agent.reset([\"preprocess\"])\n",
    "\n",
    "        end = False\n",
    "\n",
    "        while not end and frames < TRAINING_TIMES:\n",
    "            (o, end, episode) = agent.step()\n",
    "\n",
    "            # agent.render('human')\n",
    "            frames += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "        training_rwds.append(\n",
    "            np.sum([r if r is not None else 0 for (_, _, r) in agent.episode])\n",
    "        )\n",
    "        pbar.set_postfix(rwd=training_rwds[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ea829",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./training.arr\", np.asarray(training_rwds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84085436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352
         ],
         "y": [
          -21,
          -19,
          -21,
          -21,
          -19,
          -21,
          -20,
          -20,
          -21,
          -20,
          -18,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -19,
          -21,
          -21,
          -21,
          -19,
          -19,
          -20,
          -21,
          -19,
          -18,
          -18,
          -17,
          -20,
          -20,
          -20,
          -20,
          -19,
          -21,
          -21,
          -21,
          -21,
          -19,
          -19,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -18,
          -20,
          -18,
          -18,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -19,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -19,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -20,
          -20,
          -18,
          -21,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -20,
          -19,
          -18,
          -21,
          -21,
          -20,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -19,
          -20,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -19,
          -20,
          -19,
          -18,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -20,
          -20,
          -19,
          -19,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -19,
          -21,
          -20,
          -19,
          -21,
          -20,
          -19,
          -21,
          -21,
          -20,
          -21,
          -21,
          -19,
          -20,
          -20,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -18,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -19,
          -19,
          -21,
          -21,
          -20,
          -19,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -19,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -19,
          -20,
          -20,
          -21,
          -20,
          -21,
          -20,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -19,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -19,
          -19,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -19,
          -20,
          -21,
          -20,
          -20,
          -20,
          -20,
          -21,
          -21,
          -20,
          -18,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -20,
          -19,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -19,
          -21,
          -21,
          -20,
          -21,
          -20,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -18,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -18,
          -20,
          -21,
          -20,
          -21,
          -21,
          -19,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -20,
          -20,
          -19,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -21,
          -19,
          -21,
          -20,
          -20,
          -20,
          -21,
          -19,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -19,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -17,
          -21,
          -20,
          -21,
          -21,
          -20,
          -19,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -19,
          -21,
          -19,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -18,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -19,
          -21,
          -20,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -19,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -19,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -20,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -18,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -19,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -20,
          -19,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -20,
          -20,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -20,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -18,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -20,
          -18,
          -21,
          -21,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -20,
          -19,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -18,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -19,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[i + 1 for i in range(len(training_rwds))],\n",
    "               y = [r for r in training_rwds])\n",
    ")\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "# fig.update_layout(yaxis_type=\"log\")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2983d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/home/diyuan/.local/lib/python3.9/site-packages/gym/envs/atari/environment.py:267: UserWarning:\n",
      "\n",
      "\u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "\n",
      "  7%|▋         | 2/30 [00:09<02:15,  4.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000012?line=9'>10</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000012?line=11'>12</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m end \u001b[39mand\u001b[39;00m i \u001b[39m<\u001b[39m MAX_EPISODE_LENGTH:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000012?line=12'>13</a>\u001b[0m     (o, end, episode) \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000012?line=13'>14</a>\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000012?line=14'>15</a>\u001b[0m     env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/openai-gym/utils/agent.py:76\u001b[0m, in \u001b[0;36mAgent.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=69'>70</a>\u001b[0m obs \u001b[39m=\u001b[39m cast(O, obs)\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=70'>71</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode\u001b[39m.\u001b[39mappend((obs, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=72'>73</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready_act \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=73'>74</a>\u001b[0m     \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=74'>75</a>\u001b[0m     \u001b[39mif\u001b[39;00m stop\n\u001b[0;32m---> <a href='file:///~/openai-gym/utils/agent.py?line=75'>76</a>\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgm\u001b[39m.\u001b[39mtake_action(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess\u001b[39m.\u001b[39;49mget_current_state(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepisode))\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=76'>77</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=78'>79</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimprov \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgm\u001b[39m.\u001b[39mafter_step(\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=79'>80</a>\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess\u001b[39m.\u001b[39mget_current_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready_act),\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=80'>81</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess\u001b[39m.\u001b[39mtransform_history(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]),\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=81'>82</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=83'>84</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stop:\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 9'\u001b[0m in \u001b[0;36mPreprocess.get_current_state\u001b[0;34m(self, h)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=133'>134</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(h) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=135'>136</a>\u001b[0m last_4_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_4(h, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=137'>138</a>\u001b[0m rlt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrfm(i)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=138'>139</a>\u001b[0m                   \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m last_4_arr])\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=139'>140</a>\u001b[0m \u001b[39massert\u001b[39;00m rlt\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m84\u001b[39m, \u001b[39m84\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=140'>141</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rlt\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 9'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=133'>134</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(h) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=135'>136</a>\u001b[0m last_4_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_4(h, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=137'>138</a>\u001b[0m rlt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrfm(i)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=138'>139</a>\u001b[0m                   \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m last_4_arr])\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=139'>140</a>\u001b[0m \u001b[39massert\u001b[39;00m rlt\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m84\u001b[39m, \u001b[39m84\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=140'>141</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rlt\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:61\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=58'>59</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=59'>60</a>\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=60'>61</a>\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:98\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=90'>91</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=91'>92</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=92'>93</a>\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=95'>96</a>\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=96'>97</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=97'>98</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py:126\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=122'>123</a>\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=123'>124</a>\u001b[0m     pic \u001b[39m=\u001b[39m pic[:, :, \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=125'>126</a>\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(pic\u001b[39m.\u001b[39;49mtranspose((\u001b[39m2\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)))\u001b[39m.\u001b[39;49mcontiguous()\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=126'>127</a>\u001b[0m \u001b[39m# backward compatibility\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=127'>128</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EVALUATION_TIMES = 30\n",
    "MAX_EPISODE_LENGTH = 18_000\n",
    "rwds: List[int] = []\n",
    "agent.toggleImprove(False)\n",
    "\n",
    "for _ in tqdm(range(EVALUATION_TIMES)):\n",
    "    agent.reset(['preprocess'])\n",
    "\n",
    "    end = False\n",
    "    i = 1\n",
    "\n",
    "    while not end and i < MAX_EPISODE_LENGTH:\n",
    "        (o, end, episode) = agent.step()\n",
    "        i += 1\n",
    "        env.render()\n",
    "        # if end:\n",
    "        #     rwds.append(np.sum([r if r is not None else 0 for (_,\n",
    "        #                                                        _, r) in cast(Episode, episode)]))\n",
    "    rwds.append(\n",
    "        np.sum([r if r is not None else 0 for (_, _, r) in agent.episode]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b79e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./eval.arr\", np.asarray(rwds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9444528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20.928571428571427"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[i + 1 for i in range(len(rwds))],\n",
    "               y = [r for r in rwds])\n",
    ")\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "# fig.update_layout(yaxis_type=\"log\")\n",
    "fig.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
