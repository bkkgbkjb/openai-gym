{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804dd343",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "from typing import List, Tuple, Literal, Any, Optional, cast, Callable\n",
    "from utils.agent import Agent\n",
    "from tqdm.autonotebook import tqdm\n",
    "from utils.algorithm import AlgorithmInterface\n",
    "from utils.preprocess import PreprocessInterface\n",
    "import torch\n",
    "from collections import deque\n",
    "from torchvision import transforms\n",
    "import math\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "from utils.common import Step, Episode, TransitionGeneric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba56515b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4e78d9efb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d494e7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f93d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"PongNoFrameskip-v0\")\n",
    "env.seed(RANDOM_SEED)\n",
    "env.reset()\n",
    "env._max_episode_steps = 100_0000\n",
    "TOTAL_ACTIONS = env.action_space.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c43d75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7746b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape is (210, 160, 3)\n",
    "Observation = npt.NDArray[np.uint8]\n",
    "Action = int\n",
    "\n",
    "# shape is (4, 210, 160, 3)\n",
    "State = torch.Tensor\n",
    "Reward = int\n",
    "\n",
    "Transition = TransitionGeneric[State, Action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3e29eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, (8, 8), 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (4, 4), 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (3, 3), 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7 * 7 * 64, 512),\n",
    "            nn.Linear(512, TOTAL_ACTIONS),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x: State) -> torch.Tensor:\n",
    "        rlt = cast(torch.Tensor, self.net(x.to(device)))\n",
    "        return rlt.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a37d4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAlgorithm(AlgorithmInterface[State, Action]):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.times = 1\n",
    "        self.last_action = None\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def allowed_actions(self, state: State) -> List[Action]:\n",
    "        return list(range(TOTAL_ACTIONS))\n",
    "\n",
    "    def take_action(self, state: State) -> Action:\n",
    "        self.times += 1\n",
    "\n",
    "        if self.times % 10 == 0:\n",
    "            act = np.random.choice(self.allowed_actions(state))\n",
    "            self.last_action = act\n",
    "            return act\n",
    "\n",
    "        if self.last_action is not None:\n",
    "            return self.last_action\n",
    "\n",
    "        act = np.random.choice(self.allowed_actions(state))\n",
    "        self.last_action = act\n",
    "        return act\n",
    "\n",
    "    def after_step(\n",
    "        self,\n",
    "        sa: Tuple[State, Action],\n",
    "        episode: Episode[State, Action],\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def on_termination(self, episode: Episode[State, Action]):\n",
    "        pass\n",
    "\n",
    "\n",
    "class NNAlgorithm(AlgorithmInterface[State, Action]):\n",
    "    def __init__(self, nn: DQN, training_times: int = 50_00_0000, gamma: float = 0.99):\n",
    "        self.network = nn\n",
    "        self.optimizer = torch.optim.RMSprop(\n",
    "            self.network.parameters(), 1e-3, 0.95, 0.95, 1e-2\n",
    "        )\n",
    "\n",
    "        self.shrink = min(training_times / 50_00_0000, 1)\n",
    "        if self.shrink != 1:\n",
    "            print(f\"training on shrinked mode: {self.shrink}\")\n",
    "\n",
    "        self.target_network = DQN()\n",
    "        self.target_network.load_state_dict(self.network.state_dict())\n",
    "\n",
    "        self.times: int = 1\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.update_freq: int = 5\n",
    "        self.update_target = 200\n",
    "\n",
    "        self.memory_replay: deque[Transition] = deque(\n",
    "            maxlen=math.ceil(100_0000 * self.shrink)\n",
    "        )\n",
    "        self.gamma = gamma\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def allowed_actions(self, state: State) -> List[Action]:\n",
    "        return list(range(TOTAL_ACTIONS))\n",
    "\n",
    "    def take_action(self, state: State) -> Action:\n",
    "        rand = np.random.random()\n",
    "        max_decry_times = 100_0000 * self.shrink\n",
    "        sigma = -0.9 / max_decry_times * \\\n",
    "            np.min([self.times, max_decry_times]) + 1\n",
    "        if rand < sigma:\n",
    "            return np.random.choice(self.allowed_actions(state))\n",
    "        else:\n",
    "            act_vals: torch.Tensor = self.network(state)\n",
    "            maxi = torch.argmax(act_vals)\n",
    "            return cast(Action, maxi)\n",
    "\n",
    "    def after_step(\n",
    "        self,\n",
    "        sa: Tuple[State, Optional[Action]],\n",
    "        episode: Episode[State, Action],\n",
    "    ):\n",
    "        (s, a, r) = episode[-1]\n",
    "        (sn, an) = sa\n",
    "        self.memory_replay.append(\n",
    "            (s, cast(Action, a), cast(float, r), sn, an))\n",
    "\n",
    "        if self.times % self.update_freq == 0 and len(self.memory_replay) >= 48:\n",
    "\n",
    "            batch: List[Transition] = []\n",
    "            for i in np.random.randint(0, len(self.memory_replay), 32):\n",
    "                batch.append(self.memory_replay[i])\n",
    "\n",
    "            self.train(batch)\n",
    "\n",
    "        if self.times % (self.update_target * self.update_freq) == 0:\n",
    "            self.update_target_network()\n",
    "\n",
    "        self.times += 1\n",
    "\n",
    "    def on_termination(self, episode: Episode[State, Action]):\n",
    "        pass\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.network.state_dict())\n",
    "\n",
    "    def clip_reward(self, r: float) -> float:\n",
    "        if r > 0:\n",
    "            return 1.0\n",
    "        elif r < 0:\n",
    "            return -1.0\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def train(self, batch: List[Transition]):\n",
    "        target = torch.tensor(\n",
    "            [\n",
    "                self.clip_reward(r)\n",
    "                if an is None\n",
    "                else self.clip_reward(r)\n",
    "                + self.gamma * torch.max(self.target_network(sn))\n",
    "                for (_, _, r, sn, an) in batch\n",
    "            ]\n",
    "        )\n",
    "        assert target.shape == (32,)\n",
    "        x = torch.cat([self.network(s)[:, a] for (s, a, _, _, _) in batch])\n",
    "\n",
    "        assert x.shape == (32,)\n",
    "\n",
    "        loss = self.loss_func(x, target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "class Preprocess(PreprocessInterface[Observation, Action, State]):\n",
    "    def __init__(self):\n",
    "        self.trfm: Callable[[Observation], State] = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Grayscale(),\n",
    "             transforms.Resize((84, 84))]\n",
    "        )\n",
    "        self.history: Episode[State, Action] = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.history = []\n",
    "\n",
    "    def get_current_state(self, h: Episode[Observation, Action]) -> State:\n",
    "        assert len(h) > 0\n",
    "\n",
    "        last_4_arr = self.stack_4(h, -1)\n",
    "\n",
    "        rlt = torch.stack([self.trfm(i)\n",
    "                          for i in last_4_arr]).squeeze(1).unsqueeze(0)\n",
    "        assert rlt.shape == (1, 4, 84, 84)\n",
    "        return rlt\n",
    "\n",
    "    def stack_4(\n",
    "        self, h: Episode[Observation, Action], idx: int\n",
    "    ) -> npt.NDArray[np.uint8]:\n",
    "\n",
    "        assert idx < 0\n",
    "        last_4_index = [-12 + idx, -8 + idx, -4 + idx, idx]\n",
    "\n",
    "        last_4: List[Observation] = []\n",
    "        for idx in last_4_index:\n",
    "            if -idx <= len(h):\n",
    "                last_4.append(np.asarray((h[idx][0])))\n",
    "\n",
    "        last_4_arr = np.asarray(last_4)\n",
    "        while last_4_arr.shape[0] < 4:\n",
    "            last_4_arr = np.insert(last_4_arr, 0, last_4[0], axis=0)\n",
    "\n",
    "        assert last_4_arr.shape == (4, 210, 160, 3)\n",
    "\n",
    "        return last_4_arr\n",
    "\n",
    "    def transform_history(\n",
    "        self, h: Episode[Observation, Action]\n",
    "    ) -> Episode[State, Action]:\n",
    "        delta = len(h) - len(self.history)\n",
    "        assert delta == 1\n",
    "\n",
    "        (_, a, r) = h[-1]\n",
    "        last_4_arr = self.stack_4(h, -1)\n",
    "        s = torch.stack([self.trfm(i)\n",
    "                        for i in last_4_arr]).squeeze(1).unsqueeze(0)\n",
    "        assert s.shape == (1, 4, 84, 84)\n",
    "        self.history.append((s, a, r))\n",
    "\n",
    "        return self.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd632695",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on shrinked mode: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [10:58<00:00, 75.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# TRAINING_TIMES = 50_00_0000 / 20\n",
    "TRAINING_TIMES = 5_0000\n",
    "\n",
    "agent = Agent(env, NNAlgorithm(DQN(), TRAINING_TIMES), Preprocess())\n",
    "\n",
    "with tqdm(total=TRAINING_TIMES) as pbar:\n",
    "    pbar.update(1)\n",
    "    frames = 1\n",
    "    while frames < TRAINING_TIMES:\n",
    "        agent.reset(['preprocess'])\n",
    "\n",
    "        end = False\n",
    "\n",
    "        while not end and frames < TRAINING_TIMES:\n",
    "            (o, end, episode) = agent.step()\n",
    "            # if frames > TRAINING_TIMES / 5 * 2:\n",
    "            #     agent.render('human')\n",
    "            frames += 1\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd2983d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:31<03:25,  7.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=9'>10</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=11'>12</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m end \u001b[39mand\u001b[39;00m i \u001b[39m<\u001b[39m MAX_EPISODE_LENGTH:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=12'>13</a>\u001b[0m     (o, end, episode) \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=13'>14</a>\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=14'>15</a>\u001b[0m     \u001b[39m# env.render()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=15'>16</a>\u001b[0m     \u001b[39m# if end:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=16'>17</a>\u001b[0m     \u001b[39m#     rwds.append(np.sum([r if r is not None else 0 for (_,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=17'>18</a>\u001b[0m     \u001b[39m#                                                        _, r) in cast(Episode, episode)]))\u001b[39;00m\n",
      "File \u001b[0;32m~/openai-gym/utils/agent.py:73\u001b[0m, in \u001b[0;36mAgent.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=68'>69</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode\u001b[39m.\u001b[39mappend((obs, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=70'>71</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stop:\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=71'>72</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready_act \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgm\u001b[39m.\u001b[39mtake_action(\n\u001b[0;32m---> <a href='file:///~/openai-gym/utils/agent.py?line=72'>73</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess\u001b[39m.\u001b[39;49mget_current_state(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepisode)\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=73'>74</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=75'>76</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimprov \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgm\u001b[39m.\u001b[39mafter_step(\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=76'>77</a>\u001b[0m         (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess\u001b[39m.\u001b[39mget_current_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready_act),\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=77'>78</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess\u001b[39m.\u001b[39mtransform_history(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]),\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=78'>79</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=79'>80</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (obs, stop, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 8'\u001b[0m in \u001b[0;36mPreprocess.get_current_state\u001b[0;34m(self, h)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=177'>178</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(h) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=179'>180</a>\u001b[0m last_4_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_4(h, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=181'>182</a>\u001b[0m rlt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrfm(i)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=182'>183</a>\u001b[0m                   \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m last_4_arr])\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=183'>184</a>\u001b[0m \u001b[39massert\u001b[39;00m rlt\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m84\u001b[39m, \u001b[39m84\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=184'>185</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rlt\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 8'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=177'>178</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(h) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=179'>180</a>\u001b[0m last_4_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_4(h, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=181'>182</a>\u001b[0m rlt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrfm(i)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=182'>183</a>\u001b[0m                   \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m last_4_arr])\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=183'>184</a>\u001b[0m \u001b[39massert\u001b[39;00m rlt\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m84\u001b[39m, \u001b[39m84\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000007?line=184'>185</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rlt\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:61\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=58'>59</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=59'>60</a>\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=60'>61</a>\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:98\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=90'>91</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=91'>92</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=92'>93</a>\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=95'>96</a>\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=96'>97</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=97'>98</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py:129\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=126'>127</a>\u001b[0m \u001b[39m# backward compatibility\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=127'>128</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=128'>129</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=129'>130</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=130'>131</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EVALUATION_TIMES = 30\n",
    "MAX_EPISODE_LENGTH = 18_000\n",
    "rwds: List[int] = []\n",
    "agent.toggleImprove(False)\n",
    "\n",
    "for _ in tqdm(range(EVALUATION_TIMES)):\n",
    "    agent.reset(['preprocess'])\n",
    "\n",
    "    end = False\n",
    "    i = 1\n",
    "\n",
    "    while not end and i < MAX_EPISODE_LENGTH:\n",
    "        (o, end, episode) = agent.step()\n",
    "        i += 1\n",
    "        # env.render()\n",
    "        # if end:\n",
    "        #     rwds.append(np.sum([r if r is not None else 0 for (_,\n",
    "        #                                                        _, r) in cast(Episode, episode)]))\n",
    "    rwds.append(\n",
    "        np.sum([r if r is not None else 0 for (_, _, r) in agent.episode]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9444528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-21.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rwds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
