{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804dd343",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import gym\n",
    "\n",
    "from typing import List, Tuple, Literal, Any, Optional, cast, Callable\n",
    "import plotly.graph_objects as go\n",
    "from utils.agent import Agent\n",
    "from tqdm.autonotebook import tqdm\n",
    "from utils.algorithm import AlgorithmInterface\n",
    "from utils.preprocess import PreprocessInterface\n",
    "import torch\n",
    "from collections import deque\n",
    "from torchvision import transforms\n",
    "import math\n",
    "from torch import nn\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from utils.common import Step, Episode, TransitionGeneric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba56515b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11a1bca70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d494e7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f93d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gym/envs/registration.py:505: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v5` with the environment ID `ALE/Pong-v5`.\u001b[0m\n",
      "  logger.warn(\n",
      "A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Pong-v0\")\n",
    "env.seed(RANDOM_SEED)\n",
    "env.reset()\n",
    "env._max_episode_steps = 1_0000\n",
    "TOTAL_ACTIONS = env.action_space.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c43d75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7746b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape is (210, 160, 3)\n",
    "Observation = npt.NDArray[np.uint8]\n",
    "Action = int\n",
    "\n",
    "# shape is (4, 210, 160, 3)\n",
    "State = torch.Tensor\n",
    "Reward = int\n",
    "\n",
    "Transition = TransitionGeneric[State, Action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3e29eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, (8, 8), 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (4, 4), 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (3, 3), 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7 * 7 * 64, 512),\n",
    "            nn.Linear(512, TOTAL_ACTIONS),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x: State) -> torch.Tensor:\n",
    "        rlt = cast(torch.Tensor, self.net(x.to(device)))\n",
    "        assert rlt.shape == (x.shape[0], TOTAL_ACTIONS)\n",
    "        return rlt.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415e8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAlgorithm(AlgorithmInterface[State, Action]):\n",
    "    def __init__(self):\n",
    "        # self.after_step_freq = 1\n",
    "        # self.need_on_termination = True\n",
    "        self.frame_skip = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.times = 1\n",
    "        self.last_action = None\n",
    "\n",
    "    def allowed_actions(self, state: State) -> List[Action]:\n",
    "        return list(range(TOTAL_ACTIONS))\n",
    "\n",
    "    def take_action(self, state: State) -> Action:\n",
    "        self.times += 1\n",
    "\n",
    "        if self.times % 10 == 0:\n",
    "            act = np.random.choice(self.allowed_actions(state))\n",
    "            self.last_action = act\n",
    "            return act\n",
    "\n",
    "        if self.last_action is not None:\n",
    "            return self.last_action\n",
    "\n",
    "        act = np.random.choice(self.allowed_actions(state))\n",
    "        self.last_action = act\n",
    "        return act\n",
    "\n",
    "    def after_step(\n",
    "        self,\n",
    "        sa: Tuple[State, Action],\n",
    "        episode: Episode[State, Action],\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def on_termination(self, episode: Episode[State, Action]):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a37d4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TRAINING_TIMES = 12_50_0000\n",
    "\n",
    "\n",
    "class NNAlgorithm(AlgorithmInterface[State, Action]):\n",
    "    def __init__(self, nn: DQN, training_times: int = 12_50_0000, gamma: float = 0.99):\n",
    "        self.frame_skip = 3\n",
    "\n",
    "        self.times = 0\n",
    "\n",
    "        self.network = nn\n",
    "        self.optimizer = torch.optim.RMSprop(\n",
    "            self.network.parameters(), 1e-3, 0.95, 0.01\n",
    "        )\n",
    "\n",
    "        self.shrink = min(training_times / DEFAULT_TRAINING_TIMES, 1)\n",
    "        if self.shrink != 1:\n",
    "            print(f\"training on shrinked mode: {self.shrink}\")\n",
    "\n",
    "        self.target_network = DQN()\n",
    "        self.target_network.load_state_dict(self.network.state_dict())\n",
    "\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.update_target = 1000\n",
    "\n",
    "        self.memory_replay: deque[Transition] = deque(\n",
    "            maxlen=math.ceil(1_0000 * self.shrink)\n",
    "        )\n",
    "        self.gamma = gamma\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def allowed_actions(self, _: State) -> List[Action]:\n",
    "        return list(range(TOTAL_ACTIONS))\n",
    "\n",
    "    def take_action(self, state: State) -> Action:\n",
    "        rand = np.random.random()\n",
    "        max_decry_times = 100_0000 * self.shrink\n",
    "        sigma = 1 - 0.9 / max_decry_times * np.min([self.times, max_decry_times])\n",
    "        if rand < sigma:\n",
    "            return np.random.choice(self.allowed_actions(state))\n",
    "\n",
    "        else:\n",
    "            act_vals: torch.Tensor = self.network(state)\n",
    "            maxi = torch.argmax(act_vals)\n",
    "            return cast(Action, maxi)\n",
    "\n",
    "    def after_step(\n",
    "        self,\n",
    "        sa: Tuple[State, Optional[Action]],\n",
    "        episode: Episode[State, Action],\n",
    "    ):\n",
    "        (s, a, r) = episode[-1]\n",
    "        (sn, an) = sa\n",
    "        self.memory_replay.append((s, cast(Action, a), cast(float, r), sn, an))\n",
    "\n",
    "        if len(self.memory_replay) >= 1.25 * self.batch_size:\n",
    "\n",
    "            batch: List[Transition] = cast(List[Transition], [None] * self.batch_size)\n",
    "            for idx, i in enumerate(\n",
    "                np.random.choice(len(self.memory_replay), self.batch_size)\n",
    "            ):\n",
    "                batch[idx] = self.memory_replay[i]\n",
    "\n",
    "            self.train(batch)\n",
    "\n",
    "        if self.times != 0 and self.times % (self.update_target) == 0:\n",
    "            self.update_target_network()\n",
    "\n",
    "        self.times += 1\n",
    "\n",
    "    def on_termination(self, episode: Episode[State, Action]):\n",
    "        pass\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.network.state_dict())\n",
    "\n",
    "    def clip_reward(self, r: float) -> float:\n",
    "        if r > 0:\n",
    "            return 1.0\n",
    "        elif r < 0:\n",
    "            return -1.0\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def train(self, batch: List[Transition]):\n",
    "\n",
    "        masks = torch.tensor(\n",
    "            [0 if an is None else 1 for (_, _, _, _, an) in batch],\n",
    "            dtype=torch.float,\n",
    "        )\n",
    "\n",
    "        target = torch.tensor(\n",
    "            [self.clip_reward(r) for (_, _, r, _, _) in batch], dtype=torch.float\n",
    "        ) + torch.inner(\n",
    "            masks,\n",
    "            self.gamma\n",
    "            * torch.max(\n",
    "                self.network(torch.cat([sn for (_, _, _, sn, _) in batch])), dim=1\n",
    "            )[0],\n",
    "        )\n",
    "\n",
    "        assert target.shape == (32,)\n",
    "        x_vals = self.network(torch.cat([s for (s, _, _, _, _) in batch]))\n",
    "        x = x_vals[range(x_vals.shape[0]), [a for (_, a, _, _, _) in batch]]\n",
    "\n",
    "        assert x.shape == (32,)\n",
    "\n",
    "        loss = self.loss_func(x, target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "class Preprocess(PreprocessInterface[Observation, Action, State]):\n",
    "    def __init__(self):\n",
    "        self.trfm: Callable[[Observation], State] = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Grayscale(), transforms.Resize((84, 84))]\n",
    "        )\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.history: Episode[State, Action] = []\n",
    "\n",
    "    def get_current_state(self, h: Episode[Observation, Action]) -> State:\n",
    "        assert len(h) > 0\n",
    "\n",
    "        last_4_arr = self.stack_4(h, -1)\n",
    "\n",
    "        rlt = torch.cat([self.trfm(i) for i in last_4_arr]).unsqueeze(0)\n",
    "        assert rlt.shape == (1, 4, 84, 84)\n",
    "        return rlt\n",
    "\n",
    "    def stack_4(\n",
    "        self, h: Episode[Observation, Action], idx: int\n",
    "    ) -> npt.NDArray[np.uint8]:\n",
    "\n",
    "        assert idx < 0\n",
    "        last_4_index = [-12 + idx, -8 + idx, -4 + idx, idx]\n",
    "\n",
    "        last_4: List[Observation] = []\n",
    "        for idx in last_4_index:\n",
    "            if -idx <= len(h):\n",
    "                last_4.append(np.asarray((h[idx][0])))\n",
    "\n",
    "        last_4_arr = np.asarray(last_4)\n",
    "        while last_4_arr.shape[0] < 4:\n",
    "            last_4_arr = np.insert(last_4_arr, 0, last_4[0], axis=0)\n",
    "\n",
    "        assert last_4_arr.shape == (4, 210, 160, 3)\n",
    "\n",
    "        return last_4_arr\n",
    "\n",
    "    def transform_history(\n",
    "        self, h: Episode[Observation, Action]\n",
    "    ) -> Episode[State, Action]:\n",
    "        delta = len(h) - len(self.history)\n",
    "        assert delta == 1\n",
    "\n",
    "        (_, a, r) = h[-1]\n",
    "        last_4_arr = self.stack_4(h, -1)\n",
    "        s = torch.cat([self.trfm(i) for i in last_4_arr]).unsqueeze(0)\n",
    "        assert s.shape == (1, 4, 84, 84)\n",
    "        self.history.append((s, a, r))\n",
    "\n",
    "        return self.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd632695",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/600 [00:55<4:38:48, 27.97s/it, rwd=-21]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/diyuan/RLPlg2/dqn.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=13'>14</a>\u001b[0m \u001b[39m# while frames < TRAINING_TIMES:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=14'>15</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m end:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=15'>16</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=16'>17</a>\u001b[0m     \u001b[39m# end = False\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=17'>18</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=18'>19</a>\u001b[0m     \u001b[39m# while not end and frames < TRAINING_TIMES:\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=19'>20</a>\u001b[0m     (_, end, _) \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=21'>22</a>\u001b[0m     \u001b[39m# agent.render('human')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=22'>23</a>\u001b[0m     \u001b[39m# frames += 1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=23'>24</a>\u001b[0m     \u001b[39m# pbar.update(1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=25'>26</a>\u001b[0m training_rwds\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=26'>27</a>\u001b[0m     np\u001b[39m.\u001b[39msum([r \u001b[39mif\u001b[39;00m r \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m (_, _, r) \u001b[39min\u001b[39;00m agent\u001b[39m.\u001b[39mepisode])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000009?line=27'>28</a>\u001b[0m )\n",
      "File \u001b[0;32m~/RLPlg2/utils/agent.py:93\u001b[0m, in \u001b[0;36mAgent.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=82'>83</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode\u001b[39m.\u001b[39mappend((obs, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=84'>85</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready_act \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=85'>86</a>\u001b[0m     \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=86'>87</a>\u001b[0m     \u001b[39mif\u001b[39;00m stop\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=89'>90</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=90'>91</a>\u001b[0m )\n\u001b[0;32m---> <a href='file:///~/RLPlg2/utils/agent.py?line=92'>93</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimprov \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malgm\u001b[39m.\u001b[39;49mafter_step(\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=93'>94</a>\u001b[0m     (\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=94'>95</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess\u001b[39m.\u001b[39;49mget_current_state(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepisode),\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=95'>96</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mready_act,\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=96'>97</a>\u001b[0m     ),\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=97'>98</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess\u001b[39m.\u001b[39;49mtransform_history(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepisode[:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]),\n\u001b[1;32m     <a href='file:///~/RLPlg2/utils/agent.py?line=98'>99</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///~/RLPlg2/utils/agent.py?line=100'>101</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stop:\n\u001b[1;32m    <a href='file:///~/RLPlg2/utils/agent.py?line=101'>102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (obs, stop, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;32m/Users/diyuan/RLPlg2/dqn.ipynb Cell 9'\u001b[0m in \u001b[0;36mNNAlgorithm.after_step\u001b[0;34m(self, sa, episode)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=61'>62</a>\u001b[0m     \u001b[39mfor\u001b[39;00m idx, i \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=62'>63</a>\u001b[0m         np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_replay), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=63'>64</a>\u001b[0m     ):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=64'>65</a>\u001b[0m         batch[idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_replay[i]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=66'>67</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=68'>69</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimes \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimes \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=69'>70</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_target_network()\n",
      "\u001b[1;32m/Users/diyuan/RLPlg2/dqn.ipynb Cell 9'\u001b[0m in \u001b[0;36mNNAlgorithm.train\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=94'>95</a>\u001b[0m target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=95'>96</a>\u001b[0m     [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclip_reward(r) \u001b[39mfor\u001b[39;00m (_, _, r, _, _) \u001b[39min\u001b[39;00m batch], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=96'>97</a>\u001b[0m ) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39minner(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=101'>102</a>\u001b[0m     )[\u001b[39m0\u001b[39m],\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=102'>103</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=104'>105</a>\u001b[0m \u001b[39massert\u001b[39;00m target\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m32\u001b[39m,)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=105'>106</a>\u001b[0m x_vals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(torch\u001b[39m.\u001b[39;49mcat([s \u001b[39mfor\u001b[39;49;00m (s, _, _, _, _) \u001b[39min\u001b[39;49;00m batch]))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=106'>107</a>\u001b[0m x \u001b[39m=\u001b[39m x_vals[\u001b[39mrange\u001b[39m(x_vals\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), [a \u001b[39mfor\u001b[39;00m (_, a, _, _, _) \u001b[39min\u001b[39;00m batch]]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000008?line=108'>109</a>\u001b[0m \u001b[39massert\u001b[39;00m x\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m32\u001b[39m,)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/diyuan/RLPlg2/dqn.ipynb Cell 7'\u001b[0m in \u001b[0;36mDQN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000006?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: State) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000006?line=16'>17</a>\u001b[0m     rlt \u001b[39m=\u001b[39m cast(torch\u001b[39m.\u001b[39mTensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(x\u001b[39m.\u001b[39;49mto(device)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000006?line=17'>18</a>\u001b[0m     \u001b[39massert\u001b[39;00m rlt\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], TOTAL_ACTIONS)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000006?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m rlt\u001b[39m.\u001b[39mcpu()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=444'>445</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=437'>438</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRAINING_TIMES = DEFAULT_TRAINING_TIMES\n",
    "# TRAINING_TIMES = 2_0000\n",
    "\n",
    "agent = Agent(env, NNAlgorithm(DQN(), TRAINING_TIMES), Preprocess())\n",
    "training_rwds: List[float] = []\n",
    "\n",
    "with tqdm(range(600)) as pbar:\n",
    "    for _ in pbar:\n",
    "\n",
    "        # pbar.update(1)\n",
    "        # frames = 1\n",
    "        agent.reset([\"preprocess\"])\n",
    "        end = False\n",
    "        # while frames < TRAINING_TIMES:\n",
    "        while not end:\n",
    "\n",
    "            # end = False\n",
    "\n",
    "            # while not end and frames < TRAINING_TIMES:\n",
    "            (_, end, _) = agent.step()\n",
    "\n",
    "            # agent.render('human')\n",
    "            # frames += 1\n",
    "            # pbar.update(1)\n",
    "\n",
    "        training_rwds.append(\n",
    "            np.sum([r if r is not None else 0 for (_, _, r) in agent.episode])\n",
    "        )\n",
    "        pbar.set_postfix(rwd=training_rwds[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ea829",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./training.arr\", np.asarray(training_rwds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84085436",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/diyuan/RLPlg2/dqn.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000011?line=1'>2</a>\u001b[0m fig\u001b[39m.\u001b[39madd_trace(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000011?line=2'>3</a>\u001b[0m     go\u001b[39m.\u001b[39mScatter(x\u001b[39m=\u001b[39m[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(training_rwds))],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000011?line=3'>4</a>\u001b[0m                y \u001b[39m=\u001b[39m [r \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m training_rwds])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000011?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000011?line=5'>6</a>\u001b[0m \u001b[39m# fig.update_yaxes(type=\"log\")\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000011?line=6'>7</a>\u001b[0m \u001b[39m# fig.update_layout(yaxis_type=\"log\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/diyuan/RLPlg2/dqn.ipynb#ch0000011?line=7'>8</a>\u001b[0m fig\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/basedatatypes.py:3398\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/basedatatypes.py?line=3364'>3365</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/basedatatypes.py?line=3365'>3366</a>\u001b[0m \u001b[39mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/basedatatypes.py?line=3366'>3367</a>\u001b[0m \u001b[39mspecified by the renderer argument\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/basedatatypes.py?line=3393'>3394</a>\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/basedatatypes.py?line=3394'>3395</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/basedatatypes.py?line=3395'>3396</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/basedatatypes.py?line=3397'>3398</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pio\u001b[39m.\u001b[39;49mshow(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/io/_renderers.py:397\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/io/_renderers.py?line=391'>392</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/io/_renderers.py?line=392'>393</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/io/_renderers.py?line=393'>394</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/io/_renderers.py?line=395'>396</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nbformat \u001b[39mor\u001b[39;00m LooseVersion(nbformat\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m LooseVersion(\u001b[39m\"\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/io/_renderers.py?line=396'>397</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/io/_renderers.py?line=397'>398</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/io/_renderers.py?line=398'>399</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/io/_renderers.py?line=400'>401</a>\u001b[0m     ipython_display\u001b[39m.\u001b[39mdisplay(bundle, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/plotly/io/_renderers.py?line=402'>403</a>\u001b[0m \u001b[39m# external renderers\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[i + 1 for i in range(len(training_rwds))],\n",
    "               y = [r for r in training_rwds])\n",
    ")\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "# fig.update_layout(yaxis_type=\"log\")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2983d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/home/diyuan/.local/lib/python3.9/site-packages/gym/envs/atari/environment.py:267: UserWarning:\n",
      "\n",
      "\u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "\n",
      "  7%|â–‹         | 2/30 [00:09<02:15,  4.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000012?line=9'>10</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000012?line=11'>12</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m end \u001b[39mand\u001b[39;00m i \u001b[39m<\u001b[39m MAX_EPISODE_LENGTH:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000012?line=12'>13</a>\u001b[0m     (o, end, episode) \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000012?line=13'>14</a>\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000012?line=14'>15</a>\u001b[0m     env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/openai-gym/utils/agent.py:76\u001b[0m, in \u001b[0;36mAgent.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=69'>70</a>\u001b[0m obs \u001b[39m=\u001b[39m cast(O, obs)\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=70'>71</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode\u001b[39m.\u001b[39mappend((obs, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=72'>73</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready_act \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=73'>74</a>\u001b[0m     \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=74'>75</a>\u001b[0m     \u001b[39mif\u001b[39;00m stop\n\u001b[0;32m---> <a href='file:///~/openai-gym/utils/agent.py?line=75'>76</a>\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgm\u001b[39m.\u001b[39mtake_action(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess\u001b[39m.\u001b[39;49mget_current_state(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepisode))\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=76'>77</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=78'>79</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimprov \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgm\u001b[39m.\u001b[39mafter_step(\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=79'>80</a>\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess\u001b[39m.\u001b[39mget_current_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready_act),\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=80'>81</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess\u001b[39m.\u001b[39mtransform_history(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]),\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=81'>82</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=83'>84</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stop:\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 9'\u001b[0m in \u001b[0;36mPreprocess.get_current_state\u001b[0;34m(self, h)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=133'>134</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(h) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=135'>136</a>\u001b[0m last_4_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_4(h, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=137'>138</a>\u001b[0m rlt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrfm(i)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=138'>139</a>\u001b[0m                   \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m last_4_arr])\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=139'>140</a>\u001b[0m \u001b[39massert\u001b[39;00m rlt\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m84\u001b[39m, \u001b[39m84\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=140'>141</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rlt\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 9'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=133'>134</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(h) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=135'>136</a>\u001b[0m last_4_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_4(h, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=137'>138</a>\u001b[0m rlt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrfm(i)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=138'>139</a>\u001b[0m                   \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m last_4_arr])\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=139'>140</a>\u001b[0m \u001b[39massert\u001b[39;00m rlt\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m84\u001b[39m, \u001b[39m84\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000008?line=140'>141</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rlt\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:61\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=58'>59</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=59'>60</a>\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=60'>61</a>\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:98\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=90'>91</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=91'>92</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=92'>93</a>\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=95'>96</a>\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=96'>97</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=97'>98</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py:126\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=122'>123</a>\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=123'>124</a>\u001b[0m     pic \u001b[39m=\u001b[39m pic[:, :, \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=125'>126</a>\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(pic\u001b[39m.\u001b[39;49mtranspose((\u001b[39m2\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)))\u001b[39m.\u001b[39;49mcontiguous()\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=126'>127</a>\u001b[0m \u001b[39m# backward compatibility\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=127'>128</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EVALUATION_TIMES = 30\n",
    "MAX_EPISODE_LENGTH = 18_000\n",
    "rwds: List[int] = []\n",
    "agent.toggleImprove(False)\n",
    "\n",
    "for _ in tqdm(range(EVALUATION_TIMES)):\n",
    "    agent.reset(['preprocess'])\n",
    "\n",
    "    end = False\n",
    "    i = 1\n",
    "\n",
    "    while not end and i < MAX_EPISODE_LENGTH:\n",
    "        (o, end, episode) = agent.step()\n",
    "        i += 1\n",
    "        env.render()\n",
    "        # if end:\n",
    "        #     rwds.append(np.sum([r if r is not None else 0 for (_,\n",
    "        #                                                        _, r) in cast(Episode, episode)]))\n",
    "    rwds.append(\n",
    "        np.sum([r if r is not None else 0 for (_, _, r) in agent.episode]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b79e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./eval.arr\", np.asarray(rwds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9444528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20.928571428571427"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[i + 1 for i in range(len(rwds))],\n",
    "               y = [r for r in rwds])\n",
    ")\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "# fig.update_layout(yaxis_type=\"log\")\n",
    "fig.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
