{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "from typing import List, Tuple, Literal, Any, Optional, cast, Callable\n",
    "from utils.agent import Agent\n",
    "from tqdm.autonotebook import tqdm\n",
    "from utils.algorithm import AlgorithmInterface\n",
    "from utils.preprocess import PreprocessInterface\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from utils.common import Step, Episode, TransitionGeneric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8bb0c87f30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(18)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('StarGunner-v0')\n",
    "env.seed(RANDOM_SEED)\n",
    "env.reset()\n",
    "print(env.action_space)\n",
    "env._max_episode_steps = 1_8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape is (210, 160, 3)\n",
    "Observation = npt.NDArray[np.uint8]\n",
    "Action = int\n",
    "\n",
    "# shape is (4, 210, 160, 3)\n",
    "State = torch.Tensor\n",
    "Reward = int\n",
    "\n",
    "Transition = TransitionGeneric[State, Action]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        # self.first = nn.Sequential(nn.Conv2d(4, 32, (8, 8), 4), nn.ReLU()) self.second = nn.Sequential()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, (8, 8), 4), nn.ReLU(), nn.Conv2d(32, 64,  (4, 4), 2), nn.ReLU(), nn.Conv2d(64, 64, (3, 3), 1), nn.ReLU(), nn.Flatten(),  nn.Linear(7*7*64, 512), nn.Linear(512, 18)).to(device)\n",
    "\n",
    "    def forward(self, x: State) -> List[float]:\n",
    "        rlt: torch.Tensor = self.net(x.to(device))\n",
    "        return rlt.cpu().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAlgorithm(AlgorithmInterface[State, Action]):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.times = 0\n",
    "        self.last_action = None\n",
    "\n",
    "    def allowed_actions(self, state: State) -> List[Action]:\n",
    "        return list(range(18))\n",
    "\n",
    "    def take_action(self, state: State) -> Action:\n",
    "        self.times += 1\n",
    "\n",
    "        if self.times % 10 == 0:\n",
    "            act = np.random.choice(self.allowed_actions(state))\n",
    "            self.last_action = act\n",
    "            return act\n",
    "\n",
    "        if self.last_action is not None:\n",
    "            return self.last_action\n",
    "\n",
    "        act = np.random.choice(self.allowed_actions(state))\n",
    "        self.last_action = act\n",
    "        return act\n",
    "\n",
    "    def after_step(\n",
    "        self,\n",
    "        sa: Tuple[State, Action],\n",
    "        episode: Episode[State, Action],\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def on_termination(\n",
    "        self, episode: Episode[State, Action]\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "\n",
    "class NNAlgorithm(AlgorithmInterface[State, Action]):\n",
    "    def __init__(self, nn: DQN, sigma: float, gamma: float = .95):\n",
    "        self.network = nn\n",
    "        self.sigma = sigma\n",
    "\n",
    "        self.times: int = 0\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.memory_replay: List[Transition] = []\n",
    "        self.gamma = gamma\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "        self.optimizer = torch.optim.RMSprop(\n",
    "            self.network.parameters(), 1e-3, .95, .95, 1e-2)\n",
    "\n",
    "    def allowed_actions(self, state: State) -> List[Action]:\n",
    "        return list(range(18))\n",
    "\n",
    "    def take_action(self, state: State) -> Action:\n",
    "        self.times += 1\n",
    "        rand = np.random.random()\n",
    "        sigma = self.sigma * (-0.9 / 100_0000 * self.times + 1)\n",
    "        if rand < sigma:\n",
    "            return np.random.choice(self.allowed_actions(state))\n",
    "        else:\n",
    "            act_vals: torch.Tensor = self.network(state)\n",
    "            maxi = np.argmax(act_vals)\n",
    "            return cast(Action, maxi)\n",
    "\n",
    "    def after_step(\n",
    "        self,\n",
    "        sa: Tuple[State, Action],\n",
    "        episode: Episode[State, Action],\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def train(self, batch: List[Transition]):\n",
    "        # b = np.asarray(batch)\n",
    "        target = torch.tensor([r if an is None else r +\n",
    "                              self.gamma * np.max(self.network(sn)) for (s, a, r, sn, an, _) in batch])\n",
    "        assert target.shape == (32, )\n",
    "        x = torch.tensor([self.network(s)[a] for (s, a, r, _, _, _) in batch])\n",
    "        loss = self.loss_func(x, target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        pass\n",
    "\n",
    "    def extract_transitions(self, episode: Episode[State, Action]) -> List[Transition]:\n",
    "        trs: List[Transition] = []\n",
    "        for (idx, (s, a, r)) in enumerate(episode[:-1]):\n",
    "            (sn, an, rn) = episode[idx+1]\n",
    "            trs.append((s, cast(Action, a), cast(\n",
    "                float, r), sn, an, rn))\n",
    "        return trs\n",
    "\n",
    "    def on_termination(\n",
    "        self, episode: Episode[State, Action]\n",
    "    ):\n",
    "        trs = self.extract_transitions(episode)\n",
    "        for tr in trs:\n",
    "            if len(self.memory_replay) < 100_0000:\n",
    "                self.memory_replay.append(tr)\n",
    "            else:\n",
    "                self.memory_replay.pop()\n",
    "                self.memory_replay.append(tr)\n",
    "\n",
    "        if len(self.memory_replay) <= 48:\n",
    "            pass\n",
    "\n",
    "        # self.train(np.random.choice(\n",
    "        #     np.asarray(self.memory_replay), 32).tolist())\n",
    "        # self.train((np.asarray(self.memory_replay)[ np.random.randint(0, len(self.memory_replay), 32)]).tolist())\n",
    "        batch = (np.asarray(self.memory_replay))[\n",
    "            np.random.randint(0, len(self.memory_replay), 32)]\n",
    "\n",
    "        self.train(batch.tolist())\n",
    "\n",
    "\n",
    "class Preprocess(PreprocessInterface[Observation, Action, State]):\n",
    "    def __init__(self):\n",
    "        self.trfm: Callable[[Observation], State] = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Grayscale(),\n",
    "                transforms.Resize((84, 84))])\n",
    "        self.history: Episode[State, Action] = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.history = []\n",
    "\n",
    "    def get_current_state(\n",
    "        self, h: Episode[Observation, Action]\n",
    "    ) -> State:\n",
    "        assert len(h) > 0\n",
    "\n",
    "        last_4_index = [-13, -9, -5, -1]\n",
    "\n",
    "        last_4: List[Observation] = []\n",
    "        for idx in last_4_index:\n",
    "            if -idx <= len(h):\n",
    "                last_4.append(np.asarray((h[idx][0])))\n",
    "\n",
    "        last_4_arr = np.asarray(last_4)\n",
    "        while last_4_arr.shape[0] < 4:\n",
    "            last_4_arr = np.insert(last_4_arr, 0, last_4[-1:], axis=0)\n",
    "\n",
    "        assert last_4_arr.shape == (4, 210, 160, 3)\n",
    "\n",
    "        rlt = torch.stack([self.trfm(i)\n",
    "                           for i in last_4_arr]).squeeze(1).unsqueeze(0)\n",
    "        assert rlt.shape == (1, 4,  84, 84)\n",
    "        return rlt\n",
    "\n",
    "    def transform_history(\n",
    "        self, h: Episode[Observation, Action]\n",
    "    ) -> Episode[State, Action]:\n",
    "        assert len(h) > 0\n",
    "        (o, a, r) = h[-1]\n",
    "        self.history.append((self.trfm(o), a, r))\n",
    "\n",
    "        # if len(h) > l:\n",
    "        #     self.history.extend([(self.trfm(o), a, r) for (o, a, r) in h[l:]])\n",
    "        #     return self.history\n",
    "        # else:\n",
    "        return self.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(env, NNAlgorithm(DQN(), 1e-3, .95), Preprocess())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING_TIMES = 50_00_0000\n",
    "\n",
    "\n",
    "# frames = 1\n",
    "# while frames < TRAINING_TIMES:\n",
    "#     agent.reset()\n",
    "\n",
    "#     end = False\n",
    "\n",
    "#     while not end:\n",
    "#         (o, end, episode) = agent.step()\n",
    "#         frames += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/tmp/ipykernel_10073/297896916.py:110: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  batch = (np.asarray(self.memory_replay))[\n",
      "/tmp/ipykernel_10073/297896916.py:110: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  batch = (np.asarray(self.memory_replay))[\n",
      "  0%|          | 0/30 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [32, 4, 8, 8], but got 3-dimensional input of size [1, 84, 84] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=9'>10</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=11'>12</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m end \u001b[39mand\u001b[39;00m i \u001b[39m<\u001b[39m MAX_EPISODE_LENGTH:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=12'>13</a>\u001b[0m     (o, end, episode) \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=13'>14</a>\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=14'>15</a>\u001b[0m     \u001b[39m# env.render()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=15'>16</a>\u001b[0m     \u001b[39m# if end:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=16'>17</a>\u001b[0m     \u001b[39m#     rwds.append(np.sum([r if r is not None else 0 for (_,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000009?line=17'>18</a>\u001b[0m     \u001b[39m#                                                        _, r) in cast(Episode, episode)]))\u001b[39;00m\n",
      "File \u001b[0;32m~/openai-gym/utils/agent.py:78\u001b[0m, in \u001b[0;36mAgent.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=75'>76</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=76'>77</a>\u001b[0m \u001b[39m# self.episode.append((self.cur_obs, None, None))\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/openai-gym/utils/agent.py?line=77'>78</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malgm\u001b[39m.\u001b[39;49mon_termination(\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=78'>79</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess\u001b[39m.\u001b[39;49mtransform_history(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepisode))\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=79'>80</a>\u001b[0m \u001b[39m# self.episode = []\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/openai-gym/utils/agent.py?line=80'>81</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (obs, stop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode)\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 7'\u001b[0m in \u001b[0;36mNNAlgorithm.on_termination\u001b[0;34m(self, episode)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=106'>107</a>\u001b[0m \u001b[39m# self.train(np.random.choice(\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=107'>108</a>\u001b[0m \u001b[39m#     np.asarray(self.memory_replay), 32).tolist())\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=108'>109</a>\u001b[0m \u001b[39m# self.train((np.asarray(self.memory_replay)[ np.random.randint(0, len(self.memory_replay), 32)]).tolist())\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=109'>110</a>\u001b[0m batch \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_replay))[\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=110'>111</a>\u001b[0m     np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_replay), \u001b[39m32\u001b[39m)]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=112'>113</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(batch\u001b[39m.\u001b[39;49mtolist())\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 7'\u001b[0m in \u001b[0;36mNNAlgorithm.train\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=72'>73</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, batch: List[Transition]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=73'>74</a>\u001b[0m     \u001b[39m# b = np.asarray(batch)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=74'>75</a>\u001b[0m     target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([r \u001b[39mif\u001b[39;00m an \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m r \u001b[39m+\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=75'>76</a>\u001b[0m                           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork(sn)) \u001b[39mfor\u001b[39;00m (s, a, r, sn, an, _) \u001b[39min\u001b[39;00m batch])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=76'>77</a>\u001b[0m     \u001b[39massert\u001b[39;00m target\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m32\u001b[39m, )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=77'>78</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork(s)[a] \u001b[39mfor\u001b[39;00m (s, a, r, _, _, _) \u001b[39min\u001b[39;00m batch])\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 7'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=72'>73</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, batch: List[Transition]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=73'>74</a>\u001b[0m     \u001b[39m# b = np.asarray(batch)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=74'>75</a>\u001b[0m     target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([r \u001b[39mif\u001b[39;00m an \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m r \u001b[39m+\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=75'>76</a>\u001b[0m                           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmax(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(sn)) \u001b[39mfor\u001b[39;00m (s, a, r, sn, an, _) \u001b[39min\u001b[39;00m batch])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=76'>77</a>\u001b[0m     \u001b[39massert\u001b[39;00m target\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m32\u001b[39m, )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000006?line=77'>78</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork(s)[a] \u001b[39mfor\u001b[39;00m (s, a, r, _, _, _) \u001b[39min\u001b[39;00m batch])\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 6'\u001b[0m in \u001b[0;36mDQN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000005?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: State) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000005?line=8'>9</a>\u001b[0m     rlt: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(x\u001b[39m.\u001b[39;49mto(device))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000005?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m rlt\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=444'>445</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=437'>438</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [32, 4, 8, 8], but got 3-dimensional input of size [1, 84, 84] instead"
     ]
    }
   ],
   "source": [
    "EVALUATION_TIMES = 30\n",
    "MAX_EPISODE_LENGTH = 18_000\n",
    "\n",
    "rwds: List[int] = []\n",
    "\n",
    "for _ in tqdm(range(EVALUATION_TIMES)):\n",
    "    agent.reset()\n",
    "\n",
    "    end = False\n",
    "    i = 1\n",
    "\n",
    "    while not end and i < MAX_EPISODE_LENGTH:\n",
    "        (o, end, episode) = agent.step()\n",
    "        i += 1\n",
    "        # env.render()\n",
    "        # if end:\n",
    "        #     rwds.append(np.sum([r if r is not None else 0 for (_,\n",
    "        #                                                        _, r) in cast(Episode, episode)]))\n",
    "    rwds.append(np.sum([r if r is not None else 0 for (_,\n",
    "                                                       _, r) in agent.episode]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453.3333333333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rwds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
