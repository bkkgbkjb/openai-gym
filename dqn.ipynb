{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804dd343",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import gym\n",
    "\n",
    "from typing import List, Tuple, Literal, Any, Optional, cast, Callable, Union\n",
    "import plotly.graph_objects as go\n",
    "from gym.spaces import Box\n",
    "from utils.agent import Agent\n",
    "from torchvision import transforms as T\n",
    "from tqdm.autonotebook import tqdm\n",
    "from utils.algorithm import AlgorithmInterface\n",
    "from utils.preprocess import PreprocessInterface\n",
    "import torch\n",
    "from gym.wrappers import FrameStack\n",
    "from collections import deque\n",
    "from torchvision import transforms\n",
    "import math\n",
    "from torch import nn\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from utils.common import Step, Episode, TransitionGeneric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba56515b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f91b757c170>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 0\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d494e7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f93d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"PongNoFrameskip-v4\")\n",
    "env.seed(RANDOM_SEED)\n",
    "env.reset()\n",
    "TOTAL_ACTIONS = env.action_space.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c43d75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ce4895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env: gym.Env, skip: int):\n",
    "        assert skip >= 0\n",
    "\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.env = env\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, and sum reward\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = False\n",
    "        obs = None\n",
    "        info = None\n",
    "\n",
    "        for _ in range(self._skip + 1):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, info\n",
    "\n",
    "\n",
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env: gym.Env):\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.obs_shape = env.observation_space.shape[:2]\n",
    "        self.observation_space = Box(\n",
    "            low=0, high=255, shape=(1,) + self.obs_shape, dtype=np.uint8)\n",
    "\n",
    "        self.transform = T.Grayscale()\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # permute [H, W, C] array to [C, H, W] tensor\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        observation = self.transform(observation)\n",
    "        assert observation.shape == (1,) + self.obs_shape\n",
    "        return observation\n",
    "\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env: gym.Env, _shape: Union[int, Tuple[int, int]]):\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.env = env\n",
    "\n",
    "        if isinstance(_shape, int):\n",
    "            shape = (_shape, _shape)\n",
    "        else:\n",
    "            shape = _shape\n",
    "\n",
    "        self.obs_shape = self.observation_space.shape[0:1] + shape\n",
    "\n",
    "        # obs_low = self.observation_space.low\n",
    "        # obs_high = self.observation_space.high\n",
    "\n",
    "        self.observation_space = Box(\n",
    "            low=0, high=255, shape=self.obs_shape, dtype=np.uint8)\n",
    "\n",
    "        self.transforms = T.Compose(\n",
    "            [T.Resize(shape)]\n",
    "        )\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.transforms(observation)\n",
    "        assert observation.shape == self.observation_space.shape\n",
    "        return observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3835d92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FrameStack<ResizeObservation<GrayScaleObservation<SkipFrame<TimeLimit<AtariEnv<PongNoFrameskip-v4>>>>>>>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, 84)\n",
    "env = FrameStack(env, num_stack=4)\n",
    "env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7746b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape is (210, 160, 3)\n",
    "Observation = torch.Tensor\n",
    "Action = int\n",
    "\n",
    "# shape is (4, 210, 160, 3)\n",
    "State = torch.Tensor\n",
    "Reward = int\n",
    "\n",
    "Transition = TransitionGeneric[State, Action]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e29eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, (8, 8), 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (4, 4), 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (3, 3), 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7 * 7 * 64, 512),\n",
    "            nn.Linear(512, TOTAL_ACTIONS),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: State) -> torch.Tensor:\n",
    "        rlt = cast(torch.Tensor, self.net(x.to(device)))\n",
    "        assert rlt.shape == (x.shape[0], TOTAL_ACTIONS)\n",
    "        return rlt.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "415e8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAlgorithm(AlgorithmInterface[State, Action]):\n",
    "    def __init__(self):\n",
    "        # self.after_step_freq = 1\n",
    "        # self.need_on_termination = True\n",
    "        self.frame_skip = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.times = 1\n",
    "        self.last_action = None\n",
    "\n",
    "    def allowed_actions(self, state: State) -> List[Action]:\n",
    "        return list(range(TOTAL_ACTIONS))\n",
    "\n",
    "    def take_action(self, state: State) -> Action:\n",
    "        self.times += 1\n",
    "\n",
    "        if self.times % 10 == 0:\n",
    "            act = np.random.choice(self.allowed_actions(state))\n",
    "            self.last_action = act\n",
    "            return act\n",
    "\n",
    "        if self.last_action is not None:\n",
    "            return self.last_action\n",
    "\n",
    "        act = np.random.choice(self.allowed_actions(state))\n",
    "        self.last_action = act\n",
    "        return act\n",
    "\n",
    "    def after_step(\n",
    "        self,\n",
    "        sar: Tuple[State, Action, Reward],\n",
    "        sa: Tuple[State, Optional[Action]],\n",
    "    ):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a94ee723",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TRAINING_TIMES = 50_00_0000\n",
    "\n",
    "\n",
    "class NNAlgorithm(AlgorithmInterface[State, Action]):\n",
    "    def __init__(self, training_times: int = 50_00_0000, gamma: float = 0.99):\n",
    "        self.frame_skip = 0\n",
    "\n",
    "        self.times = 0\n",
    "\n",
    "        self.policy_network = DQN().to(device)\n",
    "        self.optimizer = torch.optim.RMSprop(\n",
    "            self.policy_network.parameters(), 1e-3)\n",
    "\n",
    "        self.shrink = min(training_times / DEFAULT_TRAINING_TIMES, 1)\n",
    "        if self.shrink != 1:\n",
    "            print(f\"training on shrinked mode: {self.shrink}\")\n",
    "\n",
    "        self.target_network = DQN().to(device)\n",
    "        self.target_network.load_state_dict(self.policy_network.state_dict())\n",
    "        for p in self.target_network.parameters():\n",
    "            p.requires_grad = False\n",
    "        self.target_network.eval()\n",
    "\n",
    "        self.batch_size = 32\n",
    "\n",
    "        self.update_target = 1000\n",
    "\n",
    "        self.memory_replay: deque[Transition] = deque(\n",
    "            maxlen=math.ceil(5_0000 * self.shrink)\n",
    "        )\n",
    "        self.gamma = gamma\n",
    "        self.loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def allowed_actions(self, _: State) -> List[Action]:\n",
    "        return list(range(TOTAL_ACTIONS))\n",
    "\n",
    "    def take_action(self, state: State) -> Action:\n",
    "        rand = np.random.random()\n",
    "        max_decry_times = 100_0000 * self.shrink\n",
    "        sigma = 1 - 0.9 / max_decry_times * \\\n",
    "            np.min([self.times, max_decry_times])\n",
    "        if rand < sigma:\n",
    "            return np.random.choice(self.allowed_actions(state))\n",
    "\n",
    "        else:\n",
    "            act_vals: torch.Tensor = self.policy_network(\n",
    "                torch.cat([state[0], state[1], state[2], state[3]]\n",
    "                          ).unsqueeze(0))\n",
    "            maxi = torch.argmax(act_vals)\n",
    "            return maxi.item()\n",
    "\n",
    "    def after_step(\n",
    "        self,\n",
    "        sar: Tuple[State, Action, Reward],\n",
    "        sa: Tuple[State, Optional[Action]],\n",
    "    ):\n",
    "        (s, a, r) = sar\n",
    "        (sn, an) = sa\n",
    "        self.memory_replay.append((s, a, r, sn, an))\n",
    "\n",
    "        if len(self.memory_replay) >= 1.25 * self.batch_size:\n",
    "\n",
    "            batch: List[Transition] = []\n",
    "            for i in np.random.choice(len(self.memory_replay), self.batch_size):\n",
    "                # batch[idx] = self.memory_replay[i]\n",
    "                batch.append(self.memory_replay[i])\n",
    "\n",
    "            self.train(batch)\n",
    "\n",
    "        if self.times != 0 and self.times % (self.update_target) == 0:\n",
    "            self.update_target_network()\n",
    "\n",
    "        self.times += 1\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.policy_network.state_dict())\n",
    "\n",
    "    def clip_reward(self, r: float) -> float:\n",
    "        if r > 0:\n",
    "            return 1.0\n",
    "        elif r < 0:\n",
    "            return -1.0\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "\n",
    "    def train(self, batch: List[Transition]):\n",
    "\n",
    "        masks = torch.tensor(\n",
    "            [0 if an is None else 1 for (_, _, _, _, an) in batch],\n",
    "            dtype=torch.float,\n",
    "        )\n",
    "\n",
    "\n",
    "        target = torch.tensor(\n",
    "            [self.clip_reward(r) for (_, _, r, _, _) in batch], dtype=torch.float\n",
    "        ) + torch.inner(\n",
    "            masks,\n",
    "            self.gamma\n",
    "            * torch.max(\n",
    "                self.target_network(\n",
    "                    torch.stack([torch.cat([sn[0], sn[1], sn[2], sn[3]]).squeeze(1) for (_, _, _, sn, _) in batch])),\n",
    "                dim=1,\n",
    "            )[0],\n",
    "        )\n",
    "\n",
    "        assert target.shape == (32,)\n",
    "        x_vals = self.policy_network(\n",
    "            torch.stack([torch.cat([s[0], s[1], s[2], s[3]]).squeeze(1) for (s, _, _, _, _) in batch]))\n",
    "        x = x_vals[range(x_vals.shape[0]), [a for (_, a, _, _, _) in batch]]\n",
    "\n",
    "        assert x.shape == (32,)\n",
    "\n",
    "        loss = self.loss_func(x, target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def on_termination(self, sar: Tuple[List[State], List[Action], List[Reward]]):\n",
    "        (s, a, r) = sar\n",
    "        assert len(s) == len(a) + 1\n",
    "        assert len(s) == len(r) + 1\n",
    "        pass\n",
    "    \n",
    "\n",
    "class Preprocess(PreprocessInterface[Observation, Action, State]):\n",
    "    def __init__(self):\n",
    "        # self.trfm: Callable[[Observation], State] = transforms.Compose(\n",
    "        #     [transforms.ToTensor(), transforms.Grayscale(), transforms.Resize((84, 84))]\n",
    "        # )\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def get_current_state(self, h: List[Observation]) -> State:\n",
    "        assert len(h) > 0\n",
    "\n",
    "        assert h[-1].shape == (4, 1,  84, 84)\n",
    "        return h[-1]\n",
    "\n",
    "        # last_4_arr = self.stack_4(h, -1)\n",
    "\n",
    "        # rlt = torch.cat([self.trfm(i) for i in last_4_arr]).unsqueeze(0)\n",
    "        # assert rlt.shape == (1, 4, 84, 84)\n",
    "        # return rlt\n",
    "\n",
    "    # def stack_4(self, h: List[Observation], idx: int) -> npt.NDArray[np.uint8]:\n",
    "\n",
    "    #     assert idx < 0\n",
    "    #     last_4_index = [-3 + idx, -2 + idx, -1 + idx, idx]\n",
    "\n",
    "    #     last_4: List[Observation] = []\n",
    "    #     for idx in last_4_index:\n",
    "    #         if -idx <= len(h):\n",
    "    #             last_4.append(np.asarray((h[idx])))\n",
    "\n",
    "    #     last_4_arr = np.asarray(last_4)\n",
    "    #     while last_4_arr.shape[0] < 4:\n",
    "    #         last_4_arr = np.insert(last_4_arr, 0, last_4[0], axis=0)\n",
    "\n",
    "    #     assert last_4_arr.shape == (4, 210, 160, 3)\n",
    "\n",
    "    #     return last_4_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd632695",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 323043/50000000 [44:47<114:47:52, 120.20it/s, memory_ratio=1, rwd=-20, times=0.323]      \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 12'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000011?line=18'>19</a>\u001b[0m \u001b[39m# while frames < TRAINING_TIMES:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000011?line=19'>20</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m end \u001b[39mand\u001b[39;00m frames \u001b[39m<\u001b[39m TRAINING_TIMES:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000011?line=20'>21</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000011?line=21'>22</a>\u001b[0m     \u001b[39m# end = False\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000011?line=22'>23</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000011?line=23'>24</a>\u001b[0m     \u001b[39m# while not end and frames < TRAINING_TIMES:\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000011?line=24'>25</a>\u001b[0m     (_, end) \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000011?line=25'>26</a>\u001b[0m     \u001b[39m# pbar.update(1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000011?line=26'>27</a>\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/openai-gym/utils/agent.py:99\u001b[0m, in \u001b[0;36mAgent.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=90'>91</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode_state\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=91'>92</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess\u001b[39m.\u001b[39mget_current_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode_observation)\n\u001b[1;32m     <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=92'>93</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=94'>95</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready_act \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=95'>96</a>\u001b[0m     \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m stop \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgm\u001b[39m.\u001b[39mtake_action(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode_state[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m     <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=96'>97</a>\u001b[0m )\n\u001b[0;32m---> <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=98'>99</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malgm\u001b[39m.\u001b[39;49mafter_step(\n\u001b[1;32m    <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=99'>100</a>\u001b[0m     (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepisode_state[\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepisode_action[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepisode_reward[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]),\n\u001b[1;32m    <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=100'>101</a>\u001b[0m     (\n\u001b[1;32m    <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=101'>102</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepisode_state[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=102'>103</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mready_act,\n\u001b[1;32m    <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=103'>104</a>\u001b[0m     ),\n\u001b[1;32m    <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=104'>105</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=106'>107</a>\u001b[0m \u001b[39mif\u001b[39;00m stop:\n\u001b[1;32m    <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=107'>108</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 11'\u001b[0m in \u001b[0;36mNNAlgorithm.after_step\u001b[0;34m(self, sar, sa)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=66'>67</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_replay), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=67'>68</a>\u001b[0m         \u001b[39m# batch[idx] = self.memory_replay[i]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=68'>69</a>\u001b[0m         batch\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_replay[i])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=70'>71</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=72'>73</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimes \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimes \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=73'>74</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_target_network()\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 11'\u001b[0m in \u001b[0;36mNNAlgorithm.train\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, batch: List[Transition]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=91'>92</a>\u001b[0m     masks \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=92'>93</a>\u001b[0m         [\u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m an \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m (_, _, _, _, an) \u001b[39min\u001b[39;00m batch],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=93'>94</a>\u001b[0m         dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=94'>95</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=97'>98</a>\u001b[0m     target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=98'>99</a>\u001b[0m         [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclip_reward(r) \u001b[39mfor\u001b[39;00m (_, _, r, _, _) \u001b[39min\u001b[39;00m batch], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=99'>100</a>\u001b[0m     ) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39minner(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=100'>101</a>\u001b[0m         masks,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=101'>102</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=102'>103</a>\u001b[0m         \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mmax(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=103'>104</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy_network(\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=104'>105</a>\u001b[0m                 torch\u001b[39m.\u001b[39mstack([torch\u001b[39m.\u001b[39mcat([sn[\u001b[39m0\u001b[39m], sn[\u001b[39m1\u001b[39m], sn[\u001b[39m2\u001b[39m], sn[\u001b[39m3\u001b[39m]])\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m (_, _, _, sn, _) \u001b[39min\u001b[39;00m batch])),\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=105'>106</a>\u001b[0m             dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=106'>107</a>\u001b[0m         )[\u001b[39m0\u001b[39m],\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=107'>108</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=109'>110</a>\u001b[0m     \u001b[39massert\u001b[39;00m target\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m32\u001b[39m,)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=110'>111</a>\u001b[0m     x_vals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_network(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=111'>112</a>\u001b[0m         torch\u001b[39m.\u001b[39mstack([torch\u001b[39m.\u001b[39mcat([s[\u001b[39m0\u001b[39m], s[\u001b[39m1\u001b[39m], s[\u001b[39m2\u001b[39m], s[\u001b[39m3\u001b[39m]])\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m (s, _, _, _, _) \u001b[39min\u001b[39;00m batch]))\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 11'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=89'>90</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, batch: List[Transition]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=91'>92</a>\u001b[0m     masks \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=92'>93</a>\u001b[0m         [\u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m an \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m (_, _, _, _, an) \u001b[39min\u001b[39;00m batch],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=93'>94</a>\u001b[0m         dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=94'>95</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=97'>98</a>\u001b[0m     target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=98'>99</a>\u001b[0m         [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclip_reward(r) \u001b[39mfor\u001b[39;00m (_, _, r, _, _) \u001b[39min\u001b[39;00m batch], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=99'>100</a>\u001b[0m     ) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39minner(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=100'>101</a>\u001b[0m         masks,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=101'>102</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=102'>103</a>\u001b[0m         \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mmax(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=103'>104</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy_network(\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=104'>105</a>\u001b[0m                 torch\u001b[39m.\u001b[39mstack([torch\u001b[39m.\u001b[39;49mcat([sn[\u001b[39m0\u001b[39;49m], sn[\u001b[39m1\u001b[39;49m], sn[\u001b[39m2\u001b[39;49m], sn[\u001b[39m3\u001b[39;49m]])\u001b[39m.\u001b[39;49msqueeze(\u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;00m (_, _, _, sn, _) \u001b[39min\u001b[39;00m batch])),\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=105'>106</a>\u001b[0m             dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=106'>107</a>\u001b[0m         )[\u001b[39m0\u001b[39m],\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=107'>108</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=109'>110</a>\u001b[0m     \u001b[39massert\u001b[39;00m target\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m32\u001b[39m,)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=110'>111</a>\u001b[0m     x_vals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_network(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000010?line=111'>112</a>\u001b[0m         torch\u001b[39m.\u001b[39mstack([torch\u001b[39m.\u001b[39mcat([s[\u001b[39m0\u001b[39m], s[\u001b[39m1\u001b[39m], s[\u001b[39m2\u001b[39m], s[\u001b[39m3\u001b[39m]])\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m (s, _, _, _, _) \u001b[39min\u001b[39;00m batch]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRAINING_TIMES = DEFAULT_TRAINING_TIMES\n",
    "# TRAINING_TIMES = 2_0000\n",
    "# env._max_episode_steps = 1_000\n",
    "\n",
    "agent = Agent(env, NNAlgorithm(TRAINING_TIMES), Preprocess())\n",
    "training_rwds: List[int] = []\n",
    "\n",
    "with tqdm(total=DEFAULT_TRAINING_TIMES) as pbar:\n",
    "    # for _ in pbar:\n",
    "    frames = 0\n",
    "    # pbar.update(1)\n",
    "    # pbar.update(1)\n",
    "    # frames = 1\n",
    "    while frames < TRAINING_TIMES:\n",
    "        agent.reset([\"preprocess\"])\n",
    "        # frames += 1\n",
    "        i = 0\n",
    "        end = False\n",
    "        # while frames < TRAINING_TIMES:\n",
    "        while not end and frames < TRAINING_TIMES:\n",
    "\n",
    "            # end = False\n",
    "\n",
    "            # while not end and frames < TRAINING_TIMES:\n",
    "            (_, end) = agent.step()\n",
    "            # pbar.update(1)\n",
    "            i += 1\n",
    "\n",
    "            # frames += 1\n",
    "            # pbar.update(1)\n",
    "        pbar.update(i)\n",
    "\n",
    "        training_rwds.append(np.sum([r for r in agent.episode_reward]))\n",
    "        pbar.set_postfix(\n",
    "            rwd=training_rwds[-1],\n",
    "            times=min(agent.algm.times / 100_0000, 1),\n",
    "            memory_ratio=len(agent.algm.memory_replay) / 5_0000,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264d750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.algm.times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ea829",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./training.arr\", np.asarray(training_rwds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84085436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499,
          1500,
          1501,
          1502,
          1503,
          1504,
          1505,
          1506,
          1507,
          1508,
          1509,
          1510,
          1511,
          1512,
          1513,
          1514,
          1515,
          1516,
          1517,
          1518,
          1519,
          1520,
          1521,
          1522,
          1523,
          1524,
          1525,
          1526,
          1527,
          1528,
          1529,
          1530,
          1531,
          1532,
          1533,
          1534,
          1535,
          1536,
          1537,
          1538,
          1539,
          1540,
          1541,
          1542,
          1543,
          1544,
          1545,
          1546,
          1547,
          1548,
          1549,
          1550,
          1551,
          1552,
          1553,
          1554,
          1555,
          1556,
          1557,
          1558,
          1559,
          1560,
          1561,
          1562,
          1563,
          1564,
          1565,
          1566,
          1567,
          1568,
          1569,
          1570,
          1571,
          1572,
          1573,
          1574,
          1575,
          1576,
          1577,
          1578,
          1579,
          1580,
          1581,
          1582,
          1583,
          1584,
          1585,
          1586,
          1587,
          1588,
          1589,
          1590,
          1591,
          1592,
          1593,
          1594,
          1595,
          1596,
          1597,
          1598,
          1599,
          1600,
          1601,
          1602,
          1603,
          1604,
          1605,
          1606,
          1607,
          1608,
          1609,
          1610,
          1611,
          1612,
          1613,
          1614,
          1615,
          1616,
          1617,
          1618,
          1619,
          1620,
          1621,
          1622,
          1623,
          1624,
          1625,
          1626,
          1627,
          1628,
          1629,
          1630,
          1631,
          1632,
          1633,
          1634,
          1635,
          1636,
          1637,
          1638,
          1639,
          1640,
          1641,
          1642,
          1643,
          1644,
          1645,
          1646,
          1647,
          1648,
          1649,
          1650,
          1651,
          1652,
          1653,
          1654,
          1655,
          1656,
          1657,
          1658,
          1659,
          1660,
          1661,
          1662,
          1663,
          1664,
          1665,
          1666,
          1667,
          1668,
          1669,
          1670,
          1671,
          1672,
          1673,
          1674,
          1675,
          1676,
          1677,
          1678,
          1679,
          1680,
          1681,
          1682,
          1683,
          1684,
          1685,
          1686,
          1687,
          1688,
          1689,
          1690,
          1691,
          1692,
          1693,
          1694,
          1695,
          1696,
          1697,
          1698,
          1699,
          1700,
          1701,
          1702,
          1703,
          1704,
          1705,
          1706,
          1707,
          1708,
          1709,
          1710,
          1711,
          1712,
          1713,
          1714,
          1715,
          1716,
          1717,
          1718,
          1719,
          1720,
          1721,
          1722,
          1723,
          1724,
          1725,
          1726,
          1727,
          1728,
          1729,
          1730,
          1731,
          1732,
          1733,
          1734,
          1735,
          1736,
          1737,
          1738,
          1739,
          1740,
          1741,
          1742,
          1743,
          1744,
          1745,
          1746,
          1747,
          1748,
          1749,
          1750,
          1751,
          1752,
          1753,
          1754,
          1755,
          1756,
          1757,
          1758,
          1759,
          1760,
          1761,
          1762,
          1763,
          1764,
          1765,
          1766,
          1767,
          1768,
          1769,
          1770,
          1771,
          1772,
          1773,
          1774,
          1775,
          1776,
          1777,
          1778,
          1779,
          1780,
          1781,
          1782,
          1783,
          1784,
          1785,
          1786,
          1787,
          1788,
          1789,
          1790,
          1791,
          1792,
          1793,
          1794,
          1795,
          1796,
          1797,
          1798,
          1799,
          1800,
          1801,
          1802,
          1803,
          1804,
          1805,
          1806,
          1807,
          1808,
          1809,
          1810,
          1811,
          1812,
          1813,
          1814,
          1815,
          1816,
          1817,
          1818,
          1819,
          1820,
          1821,
          1822,
          1823,
          1824,
          1825,
          1826,
          1827,
          1828,
          1829,
          1830,
          1831,
          1832,
          1833,
          1834,
          1835,
          1836,
          1837,
          1838,
          1839,
          1840,
          1841,
          1842,
          1843,
          1844,
          1845,
          1846,
          1847,
          1848,
          1849,
          1850,
          1851,
          1852,
          1853,
          1854,
          1855,
          1856,
          1857,
          1858,
          1859,
          1860,
          1861,
          1862,
          1863,
          1864,
          1865,
          1866,
          1867,
          1868,
          1869,
          1870,
          1871,
          1872,
          1873,
          1874,
          1875,
          1876,
          1877,
          1878,
          1879,
          1880,
          1881,
          1882,
          1883,
          1884,
          1885,
          1886,
          1887,
          1888,
          1889,
          1890,
          1891,
          1892,
          1893,
          1894,
          1895,
          1896,
          1897,
          1898,
          1899,
          1900,
          1901,
          1902,
          1903,
          1904,
          1905,
          1906,
          1907,
          1908,
          1909,
          1910,
          1911,
          1912,
          1913,
          1914,
          1915,
          1916,
          1917,
          1918,
          1919,
          1920,
          1921,
          1922,
          1923,
          1924,
          1925,
          1926,
          1927,
          1928,
          1929,
          1930,
          1931,
          1932,
          1933,
          1934,
          1935,
          1936,
          1937,
          1938,
          1939,
          1940,
          1941,
          1942,
          1943,
          1944,
          1945,
          1946,
          1947,
          1948,
          1949,
          1950,
          1951,
          1952,
          1953,
          1954,
          1955,
          1956,
          1957,
          1958,
          1959,
          1960,
          1961,
          1962,
          1963,
          1964,
          1965,
          1966,
          1967,
          1968,
          1969,
          1970,
          1971,
          1972,
          1973,
          1974,
          1975,
          1976,
          1977,
          1978,
          1979,
          1980,
          1981,
          1982,
          1983,
          1984,
          1985,
          1986,
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999,
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025,
          2026,
          2027,
          2028,
          2029,
          2030,
          2031,
          2032,
          2033,
          2034,
          2035,
          2036,
          2037,
          2038,
          2039,
          2040,
          2041,
          2042,
          2043,
          2044,
          2045,
          2046,
          2047,
          2048,
          2049,
          2050,
          2051,
          2052,
          2053,
          2054,
          2055,
          2056,
          2057,
          2058,
          2059,
          2060,
          2061,
          2062,
          2063,
          2064,
          2065,
          2066,
          2067,
          2068,
          2069,
          2070,
          2071,
          2072,
          2073,
          2074,
          2075,
          2076,
          2077,
          2078,
          2079,
          2080,
          2081,
          2082,
          2083,
          2084,
          2085,
          2086,
          2087,
          2088,
          2089,
          2090,
          2091,
          2092,
          2093,
          2094,
          2095,
          2096,
          2097,
          2098,
          2099,
          2100,
          2101,
          2102,
          2103,
          2104,
          2105,
          2106,
          2107,
          2108,
          2109,
          2110,
          2111,
          2112,
          2113,
          2114,
          2115,
          2116,
          2117,
          2118,
          2119,
          2120,
          2121,
          2122,
          2123,
          2124,
          2125,
          2126,
          2127,
          2128,
          2129,
          2130,
          2131,
          2132,
          2133,
          2134,
          2135,
          2136,
          2137,
          2138,
          2139,
          2140,
          2141,
          2142,
          2143,
          2144,
          2145,
          2146,
          2147,
          2148,
          2149,
          2150,
          2151,
          2152,
          2153,
          2154,
          2155,
          2156,
          2157,
          2158,
          2159,
          2160,
          2161,
          2162,
          2163,
          2164,
          2165,
          2166,
          2167,
          2168,
          2169,
          2170,
          2171,
          2172,
          2173,
          2174,
          2175,
          2176,
          2177,
          2178,
          2179,
          2180,
          2181,
          2182,
          2183,
          2184,
          2185,
          2186,
          2187,
          2188,
          2189,
          2190,
          2191,
          2192,
          2193,
          2194,
          2195,
          2196,
          2197,
          2198,
          2199,
          2200,
          2201,
          2202,
          2203,
          2204,
          2205,
          2206,
          2207,
          2208,
          2209,
          2210,
          2211,
          2212,
          2213,
          2214,
          2215,
          2216,
          2217,
          2218,
          2219,
          2220,
          2221,
          2222,
          2223,
          2224,
          2225,
          2226,
          2227,
          2228,
          2229,
          2230,
          2231,
          2232,
          2233,
          2234,
          2235,
          2236,
          2237,
          2238,
          2239,
          2240,
          2241,
          2242,
          2243,
          2244,
          2245,
          2246,
          2247,
          2248,
          2249,
          2250,
          2251,
          2252,
          2253,
          2254,
          2255,
          2256,
          2257,
          2258,
          2259,
          2260,
          2261
         ],
         "y": [
          -21,
          -19,
          -18,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -18,
          -20,
          -18,
          -20,
          -20,
          -21,
          -21,
          -20,
          -18,
          -19,
          -19,
          -19,
          -20,
          -20,
          -21,
          -19,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -19,
          -20,
          -19,
          -19,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -20,
          -19,
          -21,
          -18,
          -20,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -19,
          -21,
          -19,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -20,
          -19,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -18,
          -17,
          -21,
          -20,
          -21,
          -20,
          -19,
          -20,
          -20,
          -21,
          -19,
          -18,
          -19,
          -20,
          -20,
          -19,
          -19,
          -21,
          -20,
          -19,
          -20,
          -21,
          -18,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -19,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -20,
          -20,
          -19,
          -21,
          -19,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -18,
          -21,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -18,
          -20,
          -20,
          -19,
          -21,
          -20,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -19,
          -19,
          -21,
          -20,
          -21,
          -21,
          -17,
          -19,
          -19,
          -19,
          -20,
          -20,
          -21,
          -18,
          -21,
          -20,
          -19,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -20,
          -19,
          -21,
          -20,
          -21,
          -21,
          -20,
          -19,
          -20,
          -21,
          -18,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -17,
          -20,
          -21,
          -20,
          -19,
          -20,
          -21,
          -20,
          -20,
          -21,
          -19,
          -19,
          -19,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -20,
          -19,
          -21,
          -20,
          -19,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -18,
          -19,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -19,
          -19,
          -20,
          -20,
          -20,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -19,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -19,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -18,
          -19,
          -20,
          -20,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -18,
          -19,
          -20,
          -21,
          -20,
          -20,
          -20,
          -19,
          -21,
          -20,
          -18,
          -20,
          -21,
          -19,
          -20,
          -19,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -19,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -20,
          -19,
          -19,
          -20,
          -20,
          -20,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -19,
          -19,
          -18,
          -21,
          -21,
          -19,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -19,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -20,
          -21,
          -19,
          -21,
          -20,
          -21,
          -21,
          -21,
          -19,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -19,
          -21,
          -20,
          -21,
          -19,
          -20,
          -21,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -19,
          -21,
          -21,
          -20,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -19,
          -20,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -19,
          -19,
          -20,
          -21,
          -19,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -19,
          -20,
          -21,
          -21,
          -21,
          -21,
          -19,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -20,
          -19,
          -21,
          -21,
          -20,
          -18,
          -20,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -20,
          -21,
          -19,
          -20,
          -21,
          -19,
          -21,
          -21,
          -20,
          -20,
          -19,
          -21,
          -18,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -18,
          -19,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -19,
          -21,
          -20,
          -21,
          -19,
          -21,
          -20,
          -21,
          -21,
          -19,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -20,
          -19,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -19,
          -20,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -18,
          -19,
          -20,
          -20,
          -21,
          -21,
          -19,
          -20,
          -19,
          -19,
          -21,
          -19,
          -21,
          -20,
          -20,
          -20,
          -21,
          -20,
          -20,
          -20,
          -21,
          -20,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -18,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -20,
          -19,
          -20,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -18,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -20,
          -21,
          -18,
          -20,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -18,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -18,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -19,
          -21,
          -21,
          -21,
          -20,
          -21,
          -18,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -20,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -19,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -18,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -19,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[i + 1 for i in range(len(training_rwds))],\n",
    "               y = [r for r in training_rwds])\n",
    ")\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "# fig.update_layout(yaxis_type=\"log\")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd2983d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/home/diyuan/.local/lib/python3.9/site-packages/gym/envs/atari/environment.py:267: UserWarning: \u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "  logger.warn(\n",
      " 10%|█         | 3/30 [00:07<01:03,  2.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 16'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000015?line=9'>10</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000015?line=11'>12</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m end \u001b[39mand\u001b[39;00m i \u001b[39m<\u001b[39m MAX_EPISODE_LENGTH:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000015?line=12'>13</a>\u001b[0m     (o, end) \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000015?line=13'>14</a>\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000015?line=14'>15</a>\u001b[0m     env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/openai-gym/utils/agent.py:79\u001b[0m, in \u001b[0;36mAgent.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=75'>76</a>\u001b[0m stop: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=77'>78</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgm\u001b[39m.\u001b[39mframe_skip \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=78'>79</a>\u001b[0m     (o, r, s, _) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(act)\n\u001b[1;32m     <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=79'>80</a>\u001b[0m     rwd \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m r\n\u001b[1;32m     <a href='file:///home/diyuan/openai-gym/utils/agent.py?line=80'>81</a>\u001b[0m     obs \u001b[39m=\u001b[39m o\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gym/wrappers/frame_stack.py:115\u001b[0m, in \u001b[0;36mFrameStack.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/gym/wrappers/frame_stack.py?line=113'>114</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m--> <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/gym/wrappers/frame_stack.py?line=114'>115</a>\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/gym/wrappers/frame_stack.py?line=115'>116</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframes\u001b[39m.\u001b[39mappend(observation)\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/gym/wrappers/frame_stack.py?line=116'>117</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation(), reward, done, info\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gym/core.py:323\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/gym/core.py?line=321'>322</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m--> <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/gym/core.py?line=322'>323</a>\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/gym/core.py?line=323'>324</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation(observation), reward, done, info\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gym/core.py:324\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/gym/core.py?line=321'>322</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/gym/core.py?line=322'>323</a>\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m--> <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/gym/core.py?line=323'>324</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation(observation), reward, done, info\n",
      "\u001b[1;32m/home/diyuan/openai-gym/dqn.ipynb Cell 6'\u001b[0m in \u001b[0;36mGrayScaleObservation.observation\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000005?line=42'>43</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobservation\u001b[39m(\u001b[39mself\u001b[39m, observation):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000005?line=43'>44</a>\u001b[0m     observation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_orientation(observation)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000005?line=44'>45</a>\u001b[0m     observation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(observation)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000005?line=45'>46</a>\u001b[0m     \u001b[39massert\u001b[39;00m observation\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m1\u001b[39m,) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_shape\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diyuan/openai-gym/dqn.ipynb#ch0000005?line=46'>47</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m observation\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:1514\u001b[0m, in \u001b[0;36mGrayscale.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=1505'>1506</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=1506'>1507</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=1507'>1508</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=1508'>1509</a>\u001b[0m \u001b[39m        img (PIL Image or Tensor): Image to be converted to grayscale.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=1511'>1512</a>\u001b[0m \u001b[39m        PIL Image or Tensor: Grayscaled image.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=1512'>1513</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py?line=1513'>1514</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrgb_to_grayscale(img, num_output_channels\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_output_channels)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py:1171\u001b[0m, in \u001b[0;36mrgb_to_grayscale\u001b[0;34m(img, num_output_channels)\u001b[0m\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=1167'>1168</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m   <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=1168'>1169</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F_pil\u001b[39m.\u001b[39mto_grayscale(img, num_output_channels)\n\u001b[0;32m-> <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py?line=1170'>1171</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49mrgb_to_grayscale(img, num_output_channels)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py:146\u001b[0m, in \u001b[0;36mrgb_to_grayscale\u001b[0;34m(img, num_output_channels)\u001b[0m\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py?line=142'>143</a>\u001b[0m r, g, b \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39munbind(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py?line=143'>144</a>\u001b[0m \u001b[39m# This implementation closely follows the TF one:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py?line=144'>145</a>\u001b[0m \u001b[39m# https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/image_ops_impl.py#L2105-L2138\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py?line=145'>146</a>\u001b[0m l_img \u001b[39m=\u001b[39m (\u001b[39m0.2989\u001b[39m \u001b[39m*\u001b[39m r \u001b[39m+\u001b[39m \u001b[39m0.587\u001b[39;49m \u001b[39m*\u001b[39;49m g \u001b[39m+\u001b[39m \u001b[39m0.114\u001b[39m \u001b[39m*\u001b[39m b)\u001b[39m.\u001b[39mto(img\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py?line=146'>147</a>\u001b[0m l_img \u001b[39m=\u001b[39m l_img\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m    <a href='file:///home/diyuan/.local/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py?line=148'>149</a>\u001b[0m \u001b[39mif\u001b[39;00m num_output_channels \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EVALUATION_TIMES = 30\n",
    "MAX_EPISODE_LENGTH = 18_000\n",
    "rwds: List[int] = []\n",
    "agent.toggleEval(True)\n",
    "\n",
    "for _ in tqdm(range(EVALUATION_TIMES)):\n",
    "    agent.reset(['preprocess'])\n",
    "\n",
    "    end = False\n",
    "    i = 1\n",
    "\n",
    "    while not end and i < MAX_EPISODE_LENGTH:\n",
    "        (o, end) = agent.step()\n",
    "        i += 1\n",
    "        env.render()\n",
    "        # if end:\n",
    "        #     rwds.append(np.sum([r if r is not None else 0 for (_,\n",
    "        #                                                        _, r) in cast(Episode, episode)]))\n",
    "    rwds.append(\n",
    "        np.sum([r for r in agent.episode_reward])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b79e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./eval.arr\", np.asarray(rwds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9444528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30
         ],
         "y": [
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -19,
          -21,
          -21,
          -20,
          -21,
          -20,
          -20,
          -21,
          -20,
          -21,
          -20,
          -21,
          -21,
          -21,
          -21,
          -21,
          -21,
          -20,
          -20,
          -20,
          -21,
          -21,
          -20,
          -20
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[i + 1 for i in range(len(rwds))],\n",
    "               y = [r for r in rwds])\n",
    ")\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "# fig.update_layout(yaxis_type=\"log\")\n",
    "fig.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
